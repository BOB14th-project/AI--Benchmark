#!/usr/bin/env python3
"""
ëª¨ë¸ë³„/ì „ì²´ ì•”í˜¸í™” ì•Œê³ ë¦¬ì¦˜ íƒì§€ ì„±ê³µ/ì‹¤íŒ¨ ë¶„ì„ ë„êµ¬
"""

import json
import os
import glob
from collections import defaultdict
from typing import Dict, List, Any
import argparse


class AlgorithmDetectionAnalyzer:
    def __init__(self, results_file: str = None):
        self.results_file = results_file
        self.results_data = None
        self.ground_truth_cache = {}

    def load_results(self):
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
        if not self.results_file:
            # ìµœì‹  ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
            result_files = sorted(glob.glob("benchmark_results_*.json"), reverse=True)
            if not result_files:
                print("âŒ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            self.results_file = result_files[0]

        try:
            with open(self.results_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # ìƒˆ í˜•ì‹ ì§€ì›: detailed_resultsë¥¼ resultsë¡œ ë³€í™˜
            if 'detailed_results' in data and 'results' not in data:
                data['results'] = data['detailed_results']

            self.results_data = data
            print(f"âœ… ê²°ê³¼ íŒŒì¼ ë¡œë“œ: {self.results_file}\n")
            return True
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def load_ground_truth(self, file_name: str, agent_type: str) -> Dict[str, Any]:
        """Ground truth íŒŒì¼ ë¡œë“œ (ìºì‹±)"""
        cache_key = f"{agent_type}/{file_name}"
        if cache_key in self.ground_truth_cache:
            return self.ground_truth_cache[cache_key]

        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°
        base_name = os.path.splitext(file_name)[0]
        gt_path = f"data/ground_truth/{agent_type}/{base_name}.json"

        if not os.path.exists(gt_path):
            return {}

        try:
            with open(gt_path, 'r', encoding='utf-8') as f:
                gt_data = json.load(f)
                self.ground_truth_cache[cache_key] = gt_data
                return gt_data
        except:
            return {}

    def extract_expected_algorithms(self, ground_truth: Dict[str, Any]) -> List[str]:
        """Ground truthì—ì„œ ì˜ˆìƒ ì•Œê³ ë¦¬ì¦˜ ì¶”ì¶œ"""
        algorithms = []

        # ìƒˆ í˜•ì‹: expected_findings.vulnerable_algorithms_detected
        if 'expected_findings' in ground_truth:
            findings = ground_truth['expected_findings']
            if 'vulnerable_algorithms_detected' in findings:
                algos = findings['vulnerable_algorithms_detected']
                if isinstance(algos, list):
                    algorithms.extend([a.upper() for a in algos if isinstance(a, str)])

            # Korean algorithmsë„ ì¶”ê°€
            if 'korean_algorithms_detected' in findings:
                algos = findings['korean_algorithms_detected']
                if isinstance(algos, list):
                    algorithms.extend([a.upper() for a in algos if isinstance(a, str)])

        # ê¸°ì¡´ í˜•ì‹: algorithms í•„ë“œ
        elif 'algorithms' in ground_truth:
            for algo in ground_truth['algorithms']:
                if isinstance(algo, dict) and 'name' in algo:
                    algorithms.append(algo['name'].upper())

        return algorithms

    def extract_detected_algorithms(self, actual_response: Dict[str, Any]) -> List[str]:
        """ì‹¤ì œ ì‘ë‹µì—ì„œ íƒì§€ëœ ì•Œê³ ë¦¬ì¦˜ ì¶”ì¶œ"""
        detected = []

        if not actual_response.get('valid_json'):
            return detected

        analysis = actual_response.get('analysis_results', {})

        # algorithms_detected í•„ë“œ
        if 'algorithms_detected' in analysis:
            algos = analysis['algorithms_detected']
            if isinstance(algos, list):
                detected.extend([a.upper() for a in algos if isinstance(a, str)])

        # vulnerable_algorithms í•„ë“œ
        if 'vulnerable_algorithms' in analysis:
            algos = analysis['vulnerable_algorithms']
            if isinstance(algos, list):
                for algo in algos:
                    if isinstance(algo, str):
                        detected.append(algo.upper())
                    elif isinstance(algo, dict) and 'name' in algo:
                        detected.append(algo['name'].upper())

        # quantum_vulnerable_algorithms í•„ë“œ
        if 'quantum_vulnerable_algorithms' in analysis:
            algos = analysis['quantum_vulnerable_algorithms']
            if isinstance(algos, list):
                for algo in algos:
                    if isinstance(algo, str):
                        detected.append(algo.upper())
                    elif isinstance(algo, dict) and 'algorithm' in algo:
                        detected.append(algo['algorithm'].upper())

        # analysis_results ê°’ì—ì„œ DETECTED íŒ¨í„´ ì°¾ê¸°
        import re
        for key, value in analysis.items():
            if isinstance(value, str) and 'DETECTED:' in value.upper():
                # "DETECTED: RSA (Evidence...)" í˜•ì‹ì—ì„œ ì•Œê³ ë¦¬ì¦˜ ì¶”ì¶œ
                matches = re.findall(r'DETECTED:\s*([A-Z0-9\-/]+)', value.upper())
                detected.extend(matches)

        return list(set(detected))  # ì¤‘ë³µ ì œê±°

    def normalize_algorithm_name(self, name: str) -> str:
        """ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ ì •ê·œí™”"""
        name = name.upper().strip()

        # ë³€í˜• í†µì¼
        mappings = {
            'TRIPLE DES': '3DES',
            'TRIPLE-DES': '3DES',
            'TDES': '3DES',
            'TRIPLEDES': '3DES',
            'EC-KCDSA': 'KCDSA',
            'ECKCDSA': 'KCDSA',
            'DIFFIE-HELLMAN': 'DH',
            'DIFFIE HELLMAN': 'DH',
            'SHA1': 'SHA-1',
            'SHA256': 'SHA-256',
            'SHA512': 'SHA-512',
        }

        for pattern, replacement in mappings.items():
            if pattern in name:
                return replacement

        return name

    def check_algorithm_match(self, expected: str, detected_list: List[str]) -> bool:
        """ì•Œê³ ë¦¬ì¦˜ì´ íƒì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸ (ìœ ì—°í•œ ë§¤ì¹­)"""
        expected_norm = self.normalize_algorithm_name(expected)
        detected_norm = [self.normalize_algorithm_name(d) for d in detected_list]

        # ì •í™•í•œ ë§¤ì¹˜
        if expected_norm in detected_norm:
            return True

        # ë¶€ë¶„ ë§¤ì¹˜ (ì˜ˆ: RSA-2048 -> RSA)
        for detected in detected_norm:
            if expected_norm in detected or detected in expected_norm:
                return True

        return False

    def analyze_by_model(self) -> Dict[str, Any]:
        """ëª¨ë¸ë³„ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„"""
        model_stats = defaultdict(lambda: {
            'total_tests': 0,
            'algorithm_stats': defaultdict(lambda: {'expected': 0, 'detected': 0, 'missed': 0}),
            'total_expected': 0,
            'total_detected': 0,
            'total_missed': 0
        })

        for result in self.results_data.get('results', []):
            # í•„ë“œëª… ë§¤í•‘: model ë˜ëŠ” model_name
            model_name = result.get('model', result.get('model_name', 'unknown'))
            # íŒŒì¼ ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            file_path = result.get('file_path', result.get('file_name', ''))
            file_name = os.path.basename(file_path) if file_path else ''
            agent_type = result.get('agent_type', '')

            # Ground truth ë¡œë“œ
            gt = self.load_ground_truth(file_name, agent_type)
            if not gt:
                continue

            expected_algos = self.extract_expected_algorithms(gt)
            if not expected_algos:
                continue

            detected_algos = self.extract_detected_algorithms(result)

            stats = model_stats[model_name]
            stats['total_tests'] += 1

            # ê° ì•Œê³ ë¦¬ì¦˜ë³„ í†µê³„
            for expected in expected_algos:
                expected_norm = self.normalize_algorithm_name(expected)
                stats['algorithm_stats'][expected_norm]['expected'] += 1
                stats['total_expected'] += 1

                if self.check_algorithm_match(expected, detected_algos):
                    stats['algorithm_stats'][expected_norm]['detected'] += 1
                    stats['total_detected'] += 1
                else:
                    stats['algorithm_stats'][expected_norm]['missed'] += 1
                    stats['total_missed'] += 1

        return dict(model_stats)

    def analyze_overall(self) -> Dict[str, Any]:
        """ì „ì²´ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„ (ëª¨ë¸ êµ¬ë¶„ ì—†ì´)"""
        overall_stats = {
            'total_tests': 0,
            'algorithm_stats': defaultdict(lambda: {'expected': 0, 'detected': 0, 'missed': 0}),
            'total_expected': 0,
            'total_detected': 0,
            'total_missed': 0
        }

        for result in self.results_data.get('results', []):
            # íŒŒì¼ ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            file_path = result.get('file_path', result.get('file_name', ''))
            file_name = os.path.basename(file_path) if file_path else ''
            agent_type = result.get('agent_type', '')

            # Ground truth ë¡œë“œ
            gt = self.load_ground_truth(file_name, agent_type)
            if not gt:
                continue

            expected_algos = self.extract_expected_algorithms(gt)
            if not expected_algos:
                continue

            detected_algos = self.extract_detected_algorithms(result)

            overall_stats['total_tests'] += 1

            # ê° ì•Œê³ ë¦¬ì¦˜ë³„ í†µê³„
            for expected in expected_algos:
                expected_norm = self.normalize_algorithm_name(expected)
                overall_stats['algorithm_stats'][expected_norm]['expected'] += 1
                overall_stats['total_expected'] += 1

                if self.check_algorithm_match(expected, detected_algos):
                    overall_stats['algorithm_stats'][expected_norm]['detected'] += 1
                    overall_stats['total_detected'] += 1
                else:
                    overall_stats['algorithm_stats'][expected_norm]['missed'] += 1
                    overall_stats['total_missed'] += 1

        return overall_stats

    def print_model_analysis(self, model_stats: Dict[str, Any]):
        """ëª¨ë¸ë³„ ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("=" * 100)
        print("ğŸ“Š ëª¨ë¸ë³„ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„")
        print("=" * 100)

        for model_name, stats in sorted(model_stats.items()):
            print(f"\nğŸ¤– ëª¨ë¸: {model_name}")
            print(f"   ì´ í…ŒìŠ¤íŠ¸: {stats['total_tests']}ê°œ")
            print(f"   ì´ ì˜ˆìƒ ì•Œê³ ë¦¬ì¦˜: {stats['total_expected']}ê°œ")
            print(f"   ì´ íƒì§€ ì„±ê³µ: {stats['total_detected']}ê°œ ({stats['total_detected']/stats['total_expected']*100:.1f}%)")
            print(f"   ì´ íƒì§€ ì‹¤íŒ¨: {stats['total_missed']}ê°œ ({stats['total_missed']/stats['total_expected']*100:.1f}%)")

            print(f"\n   ğŸ“ˆ ì•Œê³ ë¦¬ì¦˜ë³„ íƒì§€ìœ¨:")

            # íƒì§€ìœ¨ ìˆœìœ¼ë¡œ ì •ë ¬
            algo_list = []
            for algo, algo_stats in stats['algorithm_stats'].items():
                detection_rate = algo_stats['detected'] / algo_stats['expected'] * 100 if algo_stats['expected'] > 0 else 0
                algo_list.append((algo, algo_stats, detection_rate))

            algo_list.sort(key=lambda x: x[2], reverse=True)

            for algo, algo_stats, detection_rate in algo_list:
                status = "âœ…" if detection_rate >= 80 else "âš ï¸" if detection_rate >= 50 else "âŒ"
                print(f"      {status} {algo:15s}: {algo_stats['detected']:3d}/{algo_stats['expected']:3d} ({detection_rate:5.1f}%)")

    def print_overall_analysis(self, overall_stats: Dict[str, Any]):
        """ì „ì²´ ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print("=" * 100)
        print("ğŸ“Š ì „ì²´ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„ (ëª¨ë“  ëª¨ë¸ í†µí•©)")
        print("=" * 100)

        print(f"\nì´ í…ŒìŠ¤íŠ¸: {overall_stats['total_tests']}ê°œ")
        print(f"ì´ ì˜ˆìƒ ì•Œê³ ë¦¬ì¦˜: {overall_stats['total_expected']}ê°œ")
        print(f"ì´ íƒì§€ ì„±ê³µ: {overall_stats['total_detected']}ê°œ ({overall_stats['total_detected']/overall_stats['total_expected']*100:.1f}%)")
        print(f"ì´ íƒì§€ ì‹¤íŒ¨: {overall_stats['total_missed']}ê°œ ({overall_stats['total_missed']/overall_stats['total_expected']*100:.1f}%)")

        print(f"\nğŸ“ˆ ì•Œê³ ë¦¬ì¦˜ë³„ íƒì§€ìœ¨:")

        # íƒì§€ìœ¨ ìˆœìœ¼ë¡œ ì •ë ¬
        algo_list = []
        for algo, algo_stats in overall_stats['algorithm_stats'].items():
            detection_rate = algo_stats['detected'] / algo_stats['expected'] * 100 if algo_stats['expected'] > 0 else 0
            algo_list.append((algo, algo_stats, detection_rate))

        algo_list.sort(key=lambda x: x[2], reverse=True)

        for algo, algo_stats, detection_rate in algo_list:
            status = "âœ…" if detection_rate >= 80 else "âš ï¸" if detection_rate >= 50 else "âŒ"
            print(f"   {status} {algo:15s}: {algo_stats['detected']:4d}/{algo_stats['expected']:4d} ({detection_rate:5.1f}%)")

        print("\n" + "=" * 100)


def main():
    parser = argparse.ArgumentParser(description='ì•Œê³ ë¦¬ì¦˜ íƒì§€ ì„±ê³µ/ì‹¤íŒ¨ ë¶„ì„ ë„êµ¬')
    parser.add_argument('--file', '-f', help='ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ JSON íŒŒì¼ (ê¸°ë³¸: ìµœì‹  íŒŒì¼)')
    parser.add_argument('--by-model', '-m', action='store_true', help='ëª¨ë¸ë³„ ë¶„ì„')
    parser.add_argument('--overall', '-o', action='store_true', help='ì „ì²´ í†µí•© ë¶„ì„')

    args = parser.parse_args()

    # ê¸°ë³¸ê°’: ë‘˜ ë‹¤ ì¶œë ¥
    if not args.by_model and not args.overall:
        args.by_model = True
        args.overall = True

    analyzer = AlgorithmDetectionAnalyzer(args.file)

    if not analyzer.load_results():
        return

    if args.by_model:
        model_stats = analyzer.analyze_by_model()
        analyzer.print_model_analysis(model_stats)
        print()

    if args.overall:
        overall_stats = analyzer.analyze_overall()
        analyzer.print_overall_analysis(overall_stats)


if __name__ == "__main__":
    main()
