# Base vs PQC-Tuned Llama ë²¤ì¹˜ë§ˆí¬ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”

**Base Llama 3.1-8B-Instruct**ì™€ **PQC-tuned Llama** (LoRA fine-tuned)ë¥¼
ê¸°ì¡´ ë²¤ì¹˜ë§ˆí‚¹ ì‹œìŠ¤í…œìœ¼ë¡œ ë¹„êµí•©ë‹ˆë‹¤.

- **í…ŒìŠ¤íŠ¸ ëŒ€ìƒ**: Assembly/Binary íŒŒì¼ë§Œ
- **ë¹„êµ ëª¨ë¸**:
  - Base: `meta-llama/Meta-Llama-3.1-8B-Instruct` (ì¼ë°˜ ëª¨ë¸)
  - Tuned: `sangwoohahn/PQCllama` (PQC íŠ¹í™” íŒŒì¸íŠœë‹)

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ï¸âƒ£ HuggingFace ë¡œê·¸ì¸ (í•„ìˆ˜)

```bash
# HuggingFace CLI ë¡œê·¸ì¸
huggingface-cli login
# í† í° ì…ë ¥: hf_xxxxx...

# Llama 3.1 ì ‘ê·¼ ê¶Œí•œ ìš”ì²­
# https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct
# "Request Access" í´ë¦­
```

### 2ï¸âƒ£ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
pip install peft accelerate
```

### 3ï¸âƒ£ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

```bash
python benchmark_base_vs_tuned_binary.py
```

---

## ğŸ“Š ì–´ë–¤ ê²ƒì„ ì¸¡ì •í•˜ë‚˜?

### í…ŒìŠ¤íŠ¸ ë°ì´í„°
- **ìœ„ì¹˜**: `data/test_files/assembly_binary/`
- **íŒŒì¼ í˜•ì‹**: Assembly ì½”ë“œ (`.s` íŒŒì¼)
- **ì˜ˆì‹œ**:
  - `aes_key_expansion_module.s`
  - `rsa_signature_verification.s`
  - `aria_encryption_engine.s`

### í‰ê°€ ì§€í‘œ

1. **Precision** (ì •ë°€ë„)
   - íƒì§€í•œ ì•Œê³ ë¦¬ì¦˜ ì¤‘ ë§ì¶˜ ë¹„ìœ¨
   - `TP / (TP + FP)`

2. **Recall** (ì¬í˜„ìœ¨)
   - ì‹¤ì œ ì•Œê³ ë¦¬ì¦˜ ì¤‘ ì°¾ì€ ë¹„ìœ¨
   - `TP / (TP + FN)`

3. **F1-Score** (ì¡°í™” í‰ê· )
   - Precisionê³¼ Recallì˜ ê· í˜•
   - `2 * (Precision * Recall) / (Precision + Recall)`

4. **Response Time** (ì‘ë‹µ ì‹œê°„)
   - ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ë° ê±¸ë¦° ì‹œê°„

---

## ğŸ¯ ì˜ˆìƒ ê²°ê³¼

### Base Model (ì¼ë°˜ Llama 3.1)
```
Precision: 20-30%
Recall: 20-30%
F1-Score: ~25%
Response Time: ~15-20ì´ˆ
```

### PQC-Tuned Model (íŒŒì¸íŠœë‹)
```
Precision: 60-80% (ì˜ˆìƒ)
Recall: 60-80% (ì˜ˆìƒ)
F1-Score: ~70% (ì˜ˆìƒ)
Response Time: ~15-20ì´ˆ
```

### ê°œì„ ìœ¨
```
ì˜ˆìƒ ê°œì„ : +180% (ì•½ 2.8ë°°)
```

---

## âš™ï¸ ì„¤ì • ì˜µì…˜

### í…ŒìŠ¤íŠ¸ ìˆ˜ ì œí•œ

```python
# benchmark_base_vs_tuned_binary.py ìˆ˜ì •

# ì „ì²´ í…ŒìŠ¤íŠ¸
TEST_LIMIT = None

# 10ê°œë§Œ í…ŒìŠ¤íŠ¸ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
TEST_LIMIT = 10

# 50ê°œ í…ŒìŠ¤íŠ¸
TEST_LIMIT = 50
```

### ë©”ëª¨ë¦¬ ìµœì í™”

Apple M2 24GBì—ì„œëŠ” ê¸°ë³¸ ì„¤ì •ìœ¼ë¡œ ì¶©ë¶„í•˜ì§€ë§Œ,
ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ:

```python
# benchmark_base_vs_tuned_binary.pyì—ì„œ
torch_dtype=torch.float16  # ì´ë¯¸ ì„¤ì •ë¨

# ë˜ëŠ” INT8 ì–‘ìí™” (ë©”ëª¨ë¦¬ ì ˆì•½)
load_in_8bit=True
```

---

## ğŸ“ ê²°ê³¼ íŒŒì¼

ê²°ê³¼ëŠ” `results/` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤:

```
results/base_vs_tuned_binary_20250106_123456.json
```

### ê²°ê³¼ êµ¬ì¡°

```json
{
  "benchmark_info": {
    "timestamp": "2025-01-06T12:34:56",
    "base_model": "meta-llama/Meta-Llama-3.1-8B-Instruct",
    "tuned_model": "sangwoohahn/PQCllama",
    "test_type": "assembly_binary",
    "total_tests": 152
  },
  "base_results": [
    {
      "test_id": "aes_key_expansion",
      "true_positives": 1,
      "false_positives": 2,
      "false_negatives": 1,
      "response_time": 15.3,
      "detected_algorithms": ["AES", "RSA", "DES"]
    }
  ],
  "tuned_results": [...]
}
```

---

## ğŸ“ˆ ê²°ê³¼ ì‹œê°í™”

ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ë ¤ë©´:

```bash
python visualize_base_vs_tuned.py results/base_vs_tuned_binary_*.json
```

ìƒì„±ë˜ëŠ” ê·¸ë˜í”„:
1. **F1-Score ë¹„êµ** (ë§‰ëŒ€ ê·¸ë˜í”„)
2. **Precision/Recall ë¹„êµ** (ì‚°ì ë„)
3. **ì‘ë‹µ ì‹œê°„ ë¹„êµ** (ë°•ìŠ¤ í”Œë¡¯)
4. **ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ëŠ¥** (íˆíŠ¸ë§µ)

---

## â±ï¸ ì˜ˆìƒ ì†Œìš” ì‹œê°„

### Apple M2 24GB ê¸°ì¤€

| í…ŒìŠ¤íŠ¸ ìˆ˜ | ì˜ˆìƒ ì‹œê°„ | ê¶Œì¥ |
|----------|----------|------|
| 10ê°œ | ~6ë¶„ | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ âœ… |
| 50ê°œ | ~30ë¶„ | ìƒ˜í”Œ í…ŒìŠ¤íŠ¸ âœ… |
| ì „ì²´ (~150ê°œ) | ~1.5ì‹œê°„ | ì „ì²´ ë²¤ì¹˜ë§ˆí¬ |

**ì°¸ê³ **: ê° ëª¨ë¸ì´ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.
- Base model: ê° í…ŒìŠ¤íŠ¸ ~15-20ì´ˆ
- Tuned model: ê° í…ŒìŠ¤íŠ¸ ~15-20ì´ˆ
- ì´: ~30-40ì´ˆ per test

---

## ğŸ” ìƒì„¸ ë¶„ì„

### 1. TP/FP/FN ë¶„ì„

```python
# ê²°ê³¼ íŒŒì¼ ë¡œë“œ
import json
with open('results/base_vs_tuned_binary_xxx.json') as f:
    data = json.load(f)

# Base model ë¶„ì„
base_tp = sum(r['true_positives'] for r in data['base_results'])
base_fp = sum(r['false_positives'] for r in data['base_results'])
base_fn = sum(r['false_negatives'] for r in data['base_results'])

print(f"Base - TP: {base_tp}, FP: {base_fp}, FN: {base_fn}")

# Tuned model ë¶„ì„
tuned_tp = sum(r['true_positives'] for r in data['tuned_results'])
tuned_fp = sum(r['false_positives'] for r in data['tuned_results'])
tuned_fn = sum(r['false_negatives'] for r in data['tuned_results'])

print(f"Tuned - TP: {tuned_tp}, FP: {tuned_fp}, FN: {tuned_fn}")
```

### 2. ì•Œê³ ë¦¬ì¦˜ë³„ ë¹„êµ

```python
from collections import defaultdict

# ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ê³µë¥ 
base_alg_success = defaultdict(lambda: {'correct': 0, 'total': 0})

for result in data['base_results']:
    expected = set(result['expected_algorithms'])
    detected = set(result['detected_algorithms'])

    for alg in expected:
        base_alg_success[alg]['total'] += 1
        if alg in detected:
            base_alg_success[alg]['correct'] += 1

# ì¶œë ¥
for alg, stats in sorted(base_alg_success.items()):
    acc = stats['correct'] / stats['total'] * 100
    print(f"{alg}: {acc:.1f}% ({stats['correct']}/{stats['total']})")
```

---

## ğŸ› ë¬¸ì œ í•´ê²°

### 1. "401 Unauthorized" ì˜¤ë¥˜

```bash
# HuggingFace ë¡œê·¸ì¸ í™•ì¸
huggingface-cli whoami

# ì¬ë¡œê·¸ì¸
huggingface-cli login

# Llama 3.1 ì ‘ê·¼ ê¶Œí•œ í™•ì¸
# https://huggingface.co/meta-llama/Meta-Llama-3.1-8B-Instruct
```

### 2. "Out of Memory" ì˜¤ë¥˜

```python
# TEST_LIMIT ì¤„ì´ê¸°
TEST_LIMIT = 10

# ë˜ëŠ” ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ì‹¤í–‰
# (ì´ë¯¸ ìˆœì°¨ ì‹¤í–‰ì´ì§€ë§Œ, í•œ ë²ˆì— í•˜ë‚˜ì”©ë§Œ)
```

### 3. "PEFT module not found"

```bash
pip install peft
```

### 4. ëŠë¦° ì‹¤í–‰ ì†ë„

```python
# í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì¤„ì´ê¸° (ì´ë¯¸ 3000ìë¡œ ì œí•œë¨)
# ë˜ëŠ” max_new_tokens ì¤„ì´ê¸°
max_new_tokens=1000  # ê¸°ë³¸ 2000
```

---

## ğŸ“ ì²´í¬ë¦¬ìŠ¤íŠ¸

ì‹¤í–‰ ì „ í™•ì¸:

- [ ] HuggingFace ë¡œê·¸ì¸ ì™„ë£Œ
- [ ] Llama 3.1 ì ‘ê·¼ ê¶Œí•œ ìŠ¹ì¸ë¨
- [ ] `peft`, `accelerate` ì„¤ì¹˜ë¨
- [ ] ë””ìŠ¤í¬ ì—¬ìœ  ê³µê°„ 20GB ì´ìƒ
- [ ] RAM 24GB ì´ìƒ (ë˜ëŠ” ì–‘ìí™” ì„¤ì •)
- [ ] `data/test_files/assembly_binary/` ì¡´ì¬

---

## ğŸ“ ì˜ˆìƒ ë°œê²¬ì‚¬í•­

### Base Model ì•½ì 
- RSA, DSA, DH ê°™ì€ ì¼ë°˜ ì•Œê³ ë¦¬ì¦˜ì€ íƒì§€
- **PQC íŠ¹í™” ì•Œê³ ë¦¬ì¦˜** (CRYSTALS, NTRU ë“±) íƒì§€ ì‹¤íŒ¨
- í•œêµ­ í‘œì¤€ (SEED, ARIA, HIGHT) íƒì§€ ë‚®ìŒ
- ì–‘ì ìœ„í˜‘ì— ëŒ€í•œ ì´í•´ ë¶€ì¡±

### Tuned Model ê°•ì 
- PQC ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ ì •í™•íˆ ì‹ë³„
- ì–‘ì ì»´í“¨íŒ… ìœ„í˜‘ì„ ì •í™•íˆ ì„¤ëª…
- CRYSTALS-Kyber, Dilithium ê°™ì€ ëŒ€ì•ˆ ì œì‹œ
- í•œêµ­ í‘œì¤€ ì•Œê³ ë¦¬ì¦˜ë„ ë” ì˜ ì¸ì‹

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ í›„:

1. **ê²°ê³¼ ë¶„ì„**
   ```bash
   python analyze_results.py results/base_vs_tuned_binary_*.json
   ```

2. **ì‹œê°í™”**
   ```bash
   python visualize_base_vs_tuned.py results/base_vs_tuned_binary_*.json
   ```

3. **ë³´ê³ ì„œ ìƒì„±**
   ```bash
   python generate_report.py results/base_vs_tuned_binary_*.json
   ```

---

## ğŸ“ ì°¸ê³ 

- **ìŠ¤í¬ë¦½íŠ¸**: `benchmark_base_vs_tuned_binary.py`
- **ë°ì´í„°**: `data/test_files/assembly_binary/`
- **ê²°ê³¼**: `results/base_vs_tuned_binary_*.json`
- **ë¡œê·¸ì¸ ê°€ì´ë“œ**: `HUGGINGFACE_LOGIN_GUIDE.md`
