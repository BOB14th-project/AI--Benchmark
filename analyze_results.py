#!/usr/bin/env python3
"""
ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„ ë„êµ¬
ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import json
import argparse
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, Any, List
import numpy as np

class ResultAnalyzer:
    def __init__(self, results_file: str):
        self.results_file = results_file
        self.results = self._load_results()
        self.ground_truth_cache = {}
        self.df = self._create_dataframe()

    def _load_results(self) -> Dict[str, Any]:
        """ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
        with open(self.results_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _load_ground_truth(self, file_path: str) -> Dict[str, Any]:
        """Ground truth íŒŒì¼ ë¡œë“œ (ìºì‹±)"""
        if file_path in self.ground_truth_cache:
            return self.ground_truth_cache[file_path]

        # file_pathì—ì„œ ground truth ê²½ë¡œ ìƒì„±
        # data/test_files/source_code/file.py -> data/ground_truth/source_code/file.json
        path = Path(file_path)
        if 'test_files' in path.parts:
            parts = list(path.parts)
            test_files_idx = parts.index('test_files')
            parts[test_files_idx] = 'ground_truth'
            gt_path = Path(*parts).with_suffix('.json')

            try:
                with open(gt_path, 'r', encoding='utf-8') as f:
                    gt_data = json.load(f)
                    self.ground_truth_cache[file_path] = gt_data
                    return gt_data
            except FileNotFoundError:
                return None
        return None

    def _calculate_precision_recall(self, detected: List[str], expected: List[str]) -> tuple:
        """Precisionê³¼ Recall ê³„ì‚°"""
        if not detected and not expected:
            return 1.0, 1.0, 1.0

        if not detected:
            return 0.0, 0.0, 0.0

        if not expected:
            return 0.0, 1.0, 0.0

        # ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  ë¹„êµ
        detected_set = set(alg.lower() for alg in detected)
        expected_set = set(alg.lower() for alg in expected)

        # ë¶€ë¶„ ë§¤ì¹­ë„ ê³ ë ¤ (ì˜ˆ: "RSA-2048" in detected, "RSA" in expected)
        true_positives = 0
        for exp in expected_set:
            for det in detected_set:
                if exp in det or det in exp:
                    true_positives += 1
                    break

        precision = true_positives / len(detected_set) if detected_set else 0.0
        recall = true_positives / len(expected_set) if expected_set else 0.0

        if precision + recall > 0:
            f1 = 2 * (precision * recall) / (precision + recall)
        else:
            f1 = 0.0

        return precision, recall, f1

    def _create_dataframe(self) -> pd.DataFrame:
        """ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        detailed_results = self.results.get('detailed_results', [])

        # ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ë§Œ í•„í„°ë§
        successful_results = [r for r in detailed_results if r.get('success', False)]

        if not successful_results:
            print("âŒ ë¶„ì„í•  ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        df = pd.DataFrame(successful_results)

        # ì¶”ê°€ ê³„ì‚° ì»¬ëŸ¼
        if not df.empty:
            df['provider_model'] = df['provider'] + '/' + df['model']
            df['total_tokens'] = df['usage'].apply(lambda x: x.get('total_tokens', 0) if isinstance(x, dict) else 0)
            df['efficiency'] = df.apply(
                lambda row: row['confidence_score'] / max(row['total_tokens'], 1) * 1000 if row['total_tokens'] > 0 else 0,
                axis=1
            )

            # ì·¨ì•½ì  ê´€ë ¨ ì»¬ëŸ¼ëª… ë³€ê²½
            if 'detected_vulnerabilities' in df.columns:
                df['detected_quantum_vulnerable_count'] = df['detected_vulnerabilities']
                df = df.drop(columns=['detected_vulnerabilities'])

            # Precision, Recall, F1 ê³„ì‚°
            print("ğŸ“Š Ground truth ê¸°ë°˜ Precision, Recall, F1 ê³„ì‚° ì¤‘...")
            precisions = []
            recalls = []
            f1_scores = []

            for idx, row in df.iterrows():
                file_path = row.get('file_path', '')
                detected_algos = row.get('detected_algorithms', [])

                # Ground truth ë¡œë“œ
                gt = self._load_ground_truth(file_path)

                if gt and 'expected_findings' in gt:
                    expected_algos = gt['expected_findings'].get('vulnerable_algorithms_detected', [])
                    precision, recall, f1 = self._calculate_precision_recall(detected_algos, expected_algos)
                else:
                    # Ground truthê°€ ì—†ìœ¼ë©´ confidence_scoreë¥¼ ê¸°ì¤€ìœ¼ë¡œ
                    precision = row['confidence_score']
                    recall = row['confidence_score']
                    f1 = row['confidence_score']

                precisions.append(precision)
                recalls.append(recall)
                f1_scores.append(f1)

            df['precision'] = precisions
            df['recall'] = recalls
            df['f1_score'] = f1_scores

            print(f"âœ… Precision, Recall, F1 ê³„ì‚° ì™„ë£Œ (í‰ê·  F1: {np.mean(f1_scores):.3f})")

        return df

    def compare_models(self, min_tests: int = 30) -> None:
        """ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ

        Args:
            min_tests: ìˆœìœ„ì— í¬í•¨ë˜ê¸° ìœ„í•œ ìµœì†Œ í…ŒìŠ¤íŠ¸ ìˆ˜ (ê¸°ë³¸ê°’: 30)
        """
        print("\n" + "=" * 60)
        print("ğŸ† ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ")
        print("=" * 60)

        if self.df.empty:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ëª¨ë¸ë³„ ì§‘ê³„
        model_stats = self.df.groupby('provider_model').agg({
            'confidence_score': ['mean', 'std', 'count'],
            'response_time': ['mean', 'std'],
            'detected_quantum_vulnerable_count': ['mean', 'std'],
            'valid_json': 'mean',
            'total_tokens': 'mean',
            'efficiency': 'mean',
            'precision': ['mean', 'std'],
            'recall': ['mean', 'std'],
            'f1_score': ['mean', 'std']
        }).round(3)

        # ì»¬ëŸ¼ëª… ì •ë¦¬
        model_stats.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in model_stats.columns]

        # F1 ì ìˆ˜ë¡œ ì •ë ¬
        model_stats = model_stats.sort_values('mean_f1_score', ascending=False)

        # í†µê³„ì  ì‹ ë¢°ë„ í‘œì‹œ
        insufficient_tests = model_stats[model_stats['count_confidence_score'] < min_tests]
        if not insufficient_tests.empty:
            print(f"\nâš ï¸  ê²½ê³ : ë‹¤ìŒ ëª¨ë¸ì€ í…ŒìŠ¤íŠ¸ ìˆ˜ê°€ ë¶€ì¡±í•˜ì—¬ í†µê³„ì  ì‹ ë¢°ë„ê°€ ë‚®ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ìµœì†Œ {min_tests}ê°œ í•„ìš”):")
            for model, stats in insufficient_tests.iterrows():
                print(f"  - {model}: {int(stats['count_confidence_score'])}ê°œ í…ŒìŠ¤íŠ¸")

        print("\nğŸ“Š ëª¨ë¸ë³„ ìƒì„¸ í†µê³„:")
        print("-" * 60)

        for model in model_stats.index:
            stats = model_stats.loc[model]
            print(f"\nğŸ¤– {model}:")
            print(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {int(stats['count_confidence_score'])}")
            print(f"  í‰ê·  ì‹ ë¢°ë„: {stats['mean_confidence_score']:.3f} (Â±{stats['std_confidence_score']:.3f})")
            print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {stats['mean_response_time']:.2f}ì´ˆ (Â±{stats['std_response_time']:.2f})")
            print(f"  í‰ê·  ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€: {stats['mean_detected_quantum_vulnerable_count']:.1f}ê°œ")
            print(f"  JSON ìœ íš¨ì„±: {stats['mean_valid_json']:.1%}")
            print(f"  í‰ê·  í† í° ì‚¬ìš©: {stats['mean_total_tokens']:.0f}")
            print(f"  íš¨ìœ¨ì„±: {stats['mean_efficiency']:.3f}")
            print(f"  Precision: {stats['mean_precision']:.3f} (Â±{stats['std_precision']:.3f})")
            print(f"  Recall: {stats['mean_recall']:.3f} (Â±{stats['std_recall']:.3f})")
            print(f"  F1 ì ìˆ˜: {stats['mean_f1_score']:.3f} (Â±{stats['std_f1_score']:.3f})")

        # ìˆœìœ„ ì¶œë ¥ (ì „ì²´)
        print(f"\nğŸ¥‡ ëª¨ë¸ ìˆœìœ„ (F1 ì ìˆ˜ ê¸°ì¤€) - ì „ì²´:")
        for i, (model, stats) in enumerate(model_stats.iterrows(), 1):
            test_count = int(stats['count_confidence_score'])
            warning = " âš ï¸ " if test_count < min_tests else ""
            print(f"  {i}. {model}: {stats['mean_f1_score']:.3f} ({test_count}ê°œ í…ŒìŠ¤íŠ¸){warning}")

        # ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ê°€ ìˆëŠ” ëª¨ë¸ë§Œ í•„í„°ë§
        reliable_models = model_stats[model_stats['count_confidence_score'] >= min_tests]
        if not reliable_models.empty and len(reliable_models) < len(model_stats):
            print(f"\nğŸ† ëª¨ë¸ ìˆœìœ„ (F1 ì ìˆ˜ ê¸°ì¤€) - ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ë§Œ (í…ŒìŠ¤íŠ¸ ìˆ˜ >= {min_tests}):")
            for i, (model, stats) in enumerate(reliable_models.iterrows(), 1):
                test_count = int(stats['count_confidence_score'])
                print(f"  {i}. {model}: {stats['mean_f1_score']:.3f} ({test_count}ê°œ í…ŒìŠ¤íŠ¸)")

    def compare_agents(self) -> None:
        """ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¹„êµ"""
        print("\n" + "=" * 60)
        print("ğŸ¯ ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„")
        print("=" * 60)

        if self.df.empty:
            return

        agent_stats = self.df.groupby('agent_type').agg({
            'confidence_score': ['mean', 'std', 'count'],
            'response_time': 'mean',
            'detected_quantum_vulnerable_count': 'mean',
            'valid_json': 'mean'
        }).round(3)

        agent_stats.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in agent_stats.columns]

        for agent in agent_stats.index:
            stats = agent_stats.loc[agent]
            print(f"\nğŸ” {agent}:")
            print(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {int(stats['count_confidence_score'])}")
            print(f"  í‰ê·  ì‹ ë¢°ë„: {stats['mean_confidence_score']:.3f} (Â±{stats['std_confidence_score']:.3f})")
            print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {stats['mean_response_time']:.2f}ì´ˆ")
            print(f"  í‰ê·  ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€: {stats['mean_detected_quantum_vulnerable_count']:.1f}ê°œ")
            print(f"  JSON ìœ íš¨ì„±: {stats['mean_valid_json']:.1%}")

    def analyze_quantum_vulnerable_algorithms(self) -> None:
        """ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„"""
        print("\n" + "=" * 60)
        print("ğŸ” ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„")
        print("=" * 60)

        if self.df.empty:
            return

        # ì „ì²´ í†µê³„
        total_tests = len(self.df)
        avg_vulnerabilities = self.df['detected_quantum_vulnerable_count'].mean()
        max_vulnerabilities = self.df['detected_quantum_vulnerable_count'].max()

        print(f"ğŸ“Š ì „ì²´ í†µê³„:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests}")
        print(f"  í‰ê·  ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€: {avg_vulnerabilities:.1f}ê°œ")
        print(f"  ìµœëŒ€ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€: {int(max_vulnerabilities)}ê°œ")

        # ëª¨ë¸ë³„ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ëŠ¥ë ¥
        vuln_by_model = self.df.groupby('provider_model')['detected_quantum_vulnerable_count'].agg(['mean', 'max', 'count'])
        vuln_by_model = vuln_by_model.sort_values('mean', ascending=False)

        print(f"\nğŸ¯ ëª¨ë¸ë³„ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ëŠ¥ë ¥:")
        for model, stats in vuln_by_model.iterrows():
            print(f"  {model}: í‰ê·  {stats['mean']:.1f}ê°œ, ìµœëŒ€ {int(stats['max'])}ê°œ ({int(stats['count'])}ê°œ í…ŒìŠ¤íŠ¸)")

        # ì—ì´ì „íŠ¸ë³„ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€
        vuln_by_agent = self.df.groupby('agent_type')['detected_quantum_vulnerable_count'].agg(['mean', 'max'])
        vuln_by_agent = vuln_by_agent.sort_values('mean', ascending=False)

        print(f"\nğŸ” ì—ì´ì „íŠ¸ë³„ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€:")
        for agent, stats in vuln_by_agent.iterrows():
            print(f"  {agent}: í‰ê·  {stats['mean']:.1f}ê°œ, ìµœëŒ€ {int(stats['max'])}ê°œ")

    def performance_analysis(self) -> None:
        """ì„±ëŠ¥ ë¶„ì„"""
        print("\n" + "=" * 60)
        print("âš¡ ì„±ëŠ¥ ë¶„ì„")
        print("=" * 60)

        if self.df.empty:
            return

        # ì‘ë‹µ ì‹œê°„ ë¶„ì„
        response_stats = self.df.groupby('provider_model')['response_time'].agg(['mean', 'min', 'max', 'std'])
        response_stats = response_stats.sort_values('mean')

        print(f"ğŸ“ˆ ì‘ë‹µ ì‹œê°„ ë¶„ì„ (ì´ˆ):")
        for model, stats in response_stats.iterrows():
            print(f"  {model}: {stats['mean']:.2f}s (Â±{stats['std']:.2f}s, ë²”ìœ„: {stats['min']:.2f}s-{stats['max']:.2f}s)")

        # í† í° íš¨ìœ¨ì„±
        if 'total_tokens' in self.df.columns:
            token_stats = self.df.groupby('provider_model')['total_tokens'].agg(['mean', 'std'])
            efficiency_stats = self.df.groupby('provider_model')['efficiency'].agg(['mean', 'std'])

            print(f"\nğŸ’° í† í° ì‚¬ìš©ëŸ‰ ë° íš¨ìœ¨ì„±:")
            for model in token_stats.index:
                token_mean = token_stats.loc[model, 'mean']
                token_std = token_stats.loc[model, 'std']
                eff_mean = efficiency_stats.loc[model, 'mean']
                print(f"  {model}: {token_mean:.0f} í† í° (Â±{token_std:.0f}), íš¨ìœ¨ì„±: {eff_mean:.3f}")

    def correlation_analysis(self) -> None:
        """ìƒê´€ê´€ê³„ ë¶„ì„"""
        print("\n" + "=" * 60)
        print("ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„")
        print("=" * 60)

        if self.df.empty or len(self.df) < 10:
            print("âŒ ìƒê´€ê´€ê³„ ë¶„ì„ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = ['confidence_score', 'response_time', 'detected_quantum_vulnerable_count', 'total_tokens']
        available_cols = [col for col in numeric_cols if col in self.df.columns]

        if len(available_cols) < 2:
            print("âŒ ìƒê´€ê´€ê³„ ë¶„ì„ì— ì¶©ë¶„í•œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        correlation_matrix = self.df[available_cols].corr()

        print("ğŸ“Š ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤:")
        print(correlation_matrix.round(3))

        # ì£¼ìš” ìƒê´€ê´€ê³„ í•´ì„
        print("\nğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­:")
        if 'confidence_score' in available_cols and 'detected_quantum_vulnerable_count' in available_cols:
            corr_conf_vuln = correlation_matrix.loc['confidence_score', 'detected_quantum_vulnerable_count']
            print(f"  ì‹ ë¢°ë„ vs ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€: {corr_conf_vuln:.3f}")

        if 'response_time' in available_cols and 'confidence_score' in available_cols:
            corr_time_conf = correlation_matrix.loc['response_time', 'confidence_score']
            print(f"  ì‘ë‹µì‹œê°„ vs ì‹ ë¢°ë„: {corr_time_conf:.3f}")

    def generate_report(self, output_file: str = None, min_tests: int = 30) -> None:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            output_file: ë¦¬í¬íŠ¸ íŒŒì¼ ê²½ë¡œ
            min_tests: ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼ë¡œ ê°„ì£¼í•˜ëŠ” ìµœì†Œ í…ŒìŠ¤íŠ¸ ìˆ˜
        """
        if output_file is None:
            output_file = f"analysis_report_{int(self.results['metadata']['timestamp'])}.txt"

        with open(output_file, 'w', encoding='utf-8') as f:
            # í—¤ë”
            f.write("=" * 80 + "\n")
            f.write("AI ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸ - ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ì„±ëŠ¥ í‰ê°€\n")
            f.write("=" * 80 + "\n\n")

            # ë©”íƒ€ë°ì´í„°
            metadata = self.results.get('metadata', {})
            f.write("ğŸ“‹ ì‹¤í–‰ ì •ë³´\n")
            f.write("-" * 80 + "\n")
            f.write(f"ì‹¤í–‰ ì‹œê°„: {metadata.get('timestamp', 'Unknown')}\n")
            f.write(f"ì´ í…ŒìŠ¤íŠ¸: {metadata.get('total_tests', 'Unknown')}\n")
            f.write(f"í”„ë¡œë°”ì´ë”: {', '.join(metadata.get('providers', []))}\n")
            f.write(f"ì—ì´ì „íŠ¸: {', '.join(metadata.get('agents', []))}\n")
            f.write(f"í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: {len(metadata.get('test_files', []))}\n\n")

            # ìš”ì•½ í†µê³„
            summary = self.results.get('summary', {})
            f.write("ğŸ“Š ìš”ì•½ í†µê³„\n")
            f.write("-" * 80 + "\n")
            f.write(f"ì„±ê³µë¥ : {summary.get('success_rate', 0):.1%}\n")
            f.write(f"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {summary.get('successful_tests', 0)}\n")
            f.write(f"ì‹¤íŒ¨í•œ í…ŒìŠ¤íŠ¸: {summary.get('failed_tests', 0)}\n")
            f.write(f"í‰ê·  ì‹ ë¢°ë„: {summary.get('avg_confidence', 0):.3f}\n")
            f.write(f"í‰ê·  ì‘ë‹µì‹œê°„: {summary.get('avg_response_time', 0):.2f}ì´ˆ\n\n")

            if self.df.empty:
                f.write("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
                return

            # ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ
            f.write("=" * 80 + "\n")
            f.write("ğŸ† ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ\n")
            f.write("=" * 80 + "\n\n")

            model_stats = self.df.groupby('provider_model').agg({
                'confidence_score': ['mean', 'std', 'min', 'max', 'count'],
                'response_time': ['mean', 'std', 'min', 'max'],
                'detected_quantum_vulnerable_count': ['mean', 'std', 'min', 'max', 'sum'],
                'valid_json': ['mean', 'sum'],
                'total_tokens': 'mean',
                'efficiency': 'mean',
                'precision': ['mean', 'std', 'min', 'max'],
                'recall': ['mean', 'std', 'min', 'max'],
                'f1_score': ['mean', 'std', 'min', 'max']
            }).round(3)

            model_stats.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in model_stats.columns]
            model_stats = model_stats.sort_values('mean_f1_score', ascending=False)

            # í†µê³„ì  ì‹ ë¢°ë„ ê²½ê³ 
            insufficient_tests = model_stats[model_stats['count_confidence_score'] < min_tests]
            if not insufficient_tests.empty:
                f.write(f"âš ï¸  ê²½ê³ : ë‹¤ìŒ ëª¨ë¸ì€ í…ŒìŠ¤íŠ¸ ìˆ˜ê°€ ë¶€ì¡±í•˜ì—¬ í†µê³„ì  ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤ (ìµœì†Œ {min_tests}ê°œ í•„ìš”):\n")
                for model, stats in insufficient_tests.iterrows():
                    f.write(f"  - {model}: {int(stats['count_confidence_score'])}ê°œ í…ŒìŠ¤íŠ¸\n")
                f.write("\n")

            for i, (model, stats) in enumerate(model_stats.iterrows(), 1):
                test_count = int(stats['count_confidence_score'])
                warning_mark = " âš ï¸  (í†µê³„ì  ì‹ ë¢°ë„ ë‚®ìŒ)" if test_count < min_tests else ""
                f.write(f"{i}. {model}{warning_mark}\n")
                f.write("-" * 80 + "\n")
                f.write(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {test_count}\n")
                f.write(f"  F1 ì ìˆ˜: {stats['mean_f1_score']:.3f} (Â±{stats['std_f1_score']:.3f}, ë²”ìœ„: {stats['min_f1_score']:.3f}~{stats['max_f1_score']:.3f})\n")
                f.write(f"  Precision: {stats['mean_precision']:.3f} (Â±{stats['std_precision']:.3f}, ë²”ìœ„: {stats['min_precision']:.3f}~{stats['max_precision']:.3f})\n")
                f.write(f"  Recall: {stats['mean_recall']:.3f} (Â±{stats['std_recall']:.3f}, ë²”ìœ„: {stats['min_recall']:.3f}~{stats['max_recall']:.3f})\n")
                f.write(f"  ì‹ ë¢°ë„ ì ìˆ˜:\n")
                f.write(f"    - í‰ê· : {stats['mean_confidence_score']:.3f} (Â±{stats['std_confidence_score']:.3f})\n")
                f.write(f"    - ë²”ìœ„: {stats['min_confidence_score']:.3f} ~ {stats['max_confidence_score']:.3f}\n")
                f.write(f"  ì‘ë‹µ ì‹œê°„ (ì´ˆ):\n")
                f.write(f"    - í‰ê· : {stats['mean_response_time']:.2f} (Â±{stats['std_response_time']:.2f})\n")
                f.write(f"    - ë²”ìœ„: {stats['min_response_time']:.2f} ~ {stats['max_response_time']:.2f}\n")
                f.write(f"  ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€:\n")
                f.write(f"    - í‰ê· : {stats['mean_detected_quantum_vulnerable_count']:.1f}ê°œ (Â±{stats['std_detected_quantum_vulnerable_count']:.1f})\n")
                f.write(f"    - ë²”ìœ„: {int(stats['min_detected_quantum_vulnerable_count'])} ~ {int(stats['max_detected_quantum_vulnerable_count'])}ê°œ\n")
                f.write(f"    - ì´í•©: {int(stats['sum_detected_quantum_vulnerable_count'])}ê°œ\n")
                f.write(f"  JSON ìœ íš¨ì„±: {stats['mean_valid_json']:.1%} ({int(stats['sum_valid_json'])}/{int(stats['count_confidence_score'])})\n")
                f.write(f"  í‰ê·  í† í° ì‚¬ìš©: {stats['mean_total_tokens']:.0f}\n")
                f.write(f"  íš¨ìœ¨ì„± (ì‹ ë¢°ë„/í† í°*1000): {stats['mean_efficiency']:.3f}\n\n")

            # ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„
            f.write("=" * 80 + "\n")
            f.write("ğŸ¯ ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„\n")
            f.write("=" * 80 + "\n\n")

            agent_stats = self.df.groupby('agent_type').agg({
                'confidence_score': ['mean', 'std', 'min', 'max', 'count'],
                'response_time': ['mean', 'std', 'min', 'max'],
                'detected_quantum_vulnerable_count': ['mean', 'std', 'min', 'max', 'sum'],
                'valid_json': 'mean'
            }).round(3)

            agent_stats.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in agent_stats.columns]

            for agent, stats in agent_stats.iterrows():
                f.write(f"ğŸ” {agent}\n")
                f.write("-" * 80 + "\n")
                f.write(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {int(stats['count_confidence_score'])}\n")
                f.write(f"  ì‹ ë¢°ë„: {stats['mean_confidence_score']:.3f} (Â±{stats['std_confidence_score']:.3f}, ë²”ìœ„: {stats['min_confidence_score']:.3f}~{stats['max_confidence_score']:.3f})\n")
                f.write(f"  ì‘ë‹µì‹œê°„: {stats['mean_response_time']:.2f}ì´ˆ (Â±{stats['std_response_time']:.2f}, ë²”ìœ„: {stats['min_response_time']:.2f}~{stats['max_response_time']:.2f})\n")
                f.write(f"  ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€: {stats['mean_detected_quantum_vulnerable_count']:.1f}ê°œ (Â±{stats['std_detected_quantum_vulnerable_count']:.1f}, ë²”ìœ„: {int(stats['min_detected_quantum_vulnerable_count'])}~{int(stats['max_detected_quantum_vulnerable_count'])}ê°œ)\n")
                f.write(f"  ì´ íƒì§€ ìˆ˜: {int(stats['sum_detected_quantum_vulnerable_count'])}ê°œ\n")
                f.write(f"  JSON ìœ íš¨ì„±: {stats['mean_valid_json']:.1%}\n\n")

            # ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„
            f.write("=" * 80 + "\n")
            f.write("ğŸ” ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ìƒì„¸ ë¶„ì„\n")
            f.write("=" * 80 + "\n\n")

            total_tests = len(self.df)
            total_detected = self.df['detected_quantum_vulnerable_count'].sum()
            avg_detected = self.df['detected_quantum_vulnerable_count'].mean()
            max_detected = self.df['detected_quantum_vulnerable_count'].max()

            f.write(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}\n")
            f.write(f"ì´ íƒì§€ ì•Œê³ ë¦¬ì¦˜ ìˆ˜: {int(total_detected)}ê°œ\n")
            f.write(f"í‰ê·  íƒì§€ ìˆ˜: {avg_detected:.1f}ê°œ\n")
            f.write(f"ìµœëŒ€ íƒì§€ ìˆ˜: {int(max_detected)}ê°œ\n\n")

            # ëª¨ë¸ë³„ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ëŠ¥ë ¥
            f.write("ğŸ“Š ëª¨ë¸ë³„ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ëŠ¥ë ¥\n")
            f.write("-" * 80 + "\n")
            vuln_by_model = self.df.groupby('provider_model')['detected_quantum_vulnerable_count'].agg(['mean', 'std', 'min', 'max', 'sum', 'count'])
            vuln_by_model = vuln_by_model.sort_values('mean', ascending=False)

            for model, stats in vuln_by_model.iterrows():
                f.write(f"{model}:\n")
                f.write(f"  í‰ê· : {stats['mean']:.1f}ê°œ (Â±{stats['std']:.1f})\n")
                f.write(f"  ë²”ìœ„: {int(stats['min'])} ~ {int(stats['max'])}ê°œ\n")
                f.write(f"  ì´í•©: {int(stats['sum'])}ê°œ ({int(stats['count'])}ê°œ í…ŒìŠ¤íŠ¸)\n\n")

            # ì—ì´ì „íŠ¸ë³„ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€
            f.write("ğŸ“Š ì—ì´ì „íŠ¸ë³„ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€\n")
            f.write("-" * 80 + "\n")
            vuln_by_agent = self.df.groupby('agent_type')['detected_quantum_vulnerable_count'].agg(['mean', 'std', 'min', 'max', 'sum', 'count'])
            vuln_by_agent = vuln_by_agent.sort_values('mean', ascending=False)

            for agent, stats in vuln_by_agent.iterrows():
                f.write(f"{agent}:\n")
                f.write(f"  í‰ê· : {stats['mean']:.1f}ê°œ (Â±{stats['std']:.1f})\n")
                f.write(f"  ë²”ìœ„: {int(stats['min'])} ~ {int(stats['max'])}ê°œ\n")
                f.write(f"  ì´í•©: {int(stats['sum'])}ê°œ ({int(stats['count'])}ê°œ í…ŒìŠ¤íŠ¸)\n\n")

            # ì„±ëŠ¥ ë¶„ì„
            f.write("=" * 80 + "\n")
            f.write("âš¡ ì„±ëŠ¥ ë¶„ì„\n")
            f.write("=" * 80 + "\n\n")

            # ì‘ë‹µ ì‹œê°„ ë¶„ì„
            f.write("ğŸ“ˆ ì‘ë‹µ ì‹œê°„ ë¶„ì„ (ì´ˆ)\n")
            f.write("-" * 80 + "\n")
            response_stats = self.df.groupby('provider_model')['response_time'].agg(['mean', 'std', 'min', 'max', 'median'])
            response_stats = response_stats.sort_values('mean')

            for model, stats in response_stats.iterrows():
                f.write(f"{model}:\n")
                f.write(f"  í‰ê· : {stats['mean']:.2f}ì´ˆ (Â±{stats['std']:.2f})\n")
                f.write(f"  ì¤‘ì•™ê°’: {stats['median']:.2f}ì´ˆ\n")
                f.write(f"  ë²”ìœ„: {stats['min']:.2f} ~ {stats['max']:.2f}ì´ˆ\n\n")

            # í† í° íš¨ìœ¨ì„±
            if 'total_tokens' in self.df.columns and self.df['total_tokens'].sum() > 0:
                f.write("ğŸ’° í† í° ì‚¬ìš©ëŸ‰ ë° íš¨ìœ¨ì„±\n")
                f.write("-" * 80 + "\n")
                token_stats = self.df.groupby('provider_model').agg({
                    'total_tokens': ['mean', 'std', 'sum'],
                    'efficiency': 'mean'
                }).round(3)
                token_stats.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in token_stats.columns]

                for model in token_stats.index:
                    f.write(f"{model}:\n")
                    f.write(f"  í‰ê·  í† í°: {token_stats.loc[model, 'mean_total_tokens']:.0f} (Â±{token_stats.loc[model, 'std_total_tokens']:.0f})\n")
                    f.write(f"  ì´ í† í°: {token_stats.loc[model, 'sum_total_tokens']:.0f}\n")
                    f.write(f"  íš¨ìœ¨ì„±: {token_stats.loc[model, 'mean_efficiency']:.3f}\n\n")

            # ìƒê´€ê´€ê³„ ë¶„ì„
            if len(self.df) >= 10:
                f.write("=" * 80 + "\n")
                f.write("ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„\n")
                f.write("=" * 80 + "\n\n")

                numeric_cols = ['confidence_score', 'response_time', 'detected_quantum_vulnerable_count', 'total_tokens']
                available_cols = [col for col in numeric_cols if col in self.df.columns]

                if len(available_cols) >= 2:
                    correlation_matrix = self.df[available_cols].corr()
                    f.write("ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤:\n")
                    f.write("-" * 80 + "\n")
                    f.write(correlation_matrix.to_string())
                    f.write("\n\n")

                    # ì£¼ìš” ìƒê´€ê´€ê³„ í•´ì„
                    f.write("ì£¼ìš” ë°œê²¬ì‚¬í•­:\n")
                    f.write("-" * 80 + "\n")
                    if 'confidence_score' in available_cols and 'detected_quantum_vulnerable_count' in available_cols:
                        corr = correlation_matrix.loc['confidence_score', 'detected_quantum_vulnerable_count']
                        f.write(f"ì‹ ë¢°ë„ vs ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€: {corr:.3f}\n")
                    if 'response_time' in available_cols and 'confidence_score' in available_cols:
                        corr = correlation_matrix.loc['response_time', 'confidence_score']
                        f.write(f"ì‘ë‹µì‹œê°„ vs ì‹ ë¢°ë„: {corr:.3f}\n")
                    if 'total_tokens' in available_cols and 'confidence_score' in available_cols:
                        corr = correlation_matrix.loc['total_tokens', 'confidence_score']
                        f.write(f"í† í° ì‚¬ìš©ëŸ‰ vs ì‹ ë¢°ë„: {corr:.3f}\n")
                    f.write("\n")

            # ëª¨ë¸-ì—ì´ì „íŠ¸ ì¡°í•©ë³„ ì„±ëŠ¥
            f.write("=" * 80 + "\n")
            f.write("ğŸ”¬ ëª¨ë¸-ì—ì´ì „íŠ¸ ì¡°í•©ë³„ ìƒì„¸ ì„±ëŠ¥\n")
            f.write("=" * 80 + "\n\n")

            combo_stats = self.df.groupby(['provider_model', 'agent_type']).agg({
                'confidence_score': ['mean', 'std', 'count'],
                'response_time': 'mean',
                'detected_quantum_vulnerable_count': ['mean', 'sum']
            }).round(3)

            combo_stats.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in combo_stats.columns]

            for (model, agent), stats in combo_stats.iterrows():
                f.write(f"{model} + {agent}:\n")
                f.write(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {int(stats['count_confidence_score'])}\n")
                f.write(f"  í‰ê·  ì‹ ë¢°ë„: {stats['mean_confidence_score']:.3f} (Â±{stats['std_confidence_score']:.3f})\n")
                f.write(f"  í‰ê·  ì‘ë‹µì‹œê°„: {stats['mean_response_time']:.2f}ì´ˆ\n")
                f.write(f"  í‰ê·  íƒì§€: {stats['mean_detected_quantum_vulnerable_count']:.1f}ê°œ (ì´ {int(stats['sum_detected_quantum_vulnerable_count'])}ê°œ)\n\n")

            # ì¢…í•© ê²°ë¡ 
            f.write("=" * 80 + "\n")
            f.write("ğŸ“Œ ì¢…í•© ê²°ë¡ \n")
            f.write("=" * 80 + "\n\n")

            # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ëª¨ë¸ (ì¶©ë¶„í•œ í…ŒìŠ¤íŠ¸ ìˆ˜)
            reliable_models = model_stats[model_stats['count_confidence_score'] >= min_tests]

            if not reliable_models.empty:
                best_reliable_model = reliable_models.index[0]
                f.write(f"âœ… ìµœê³  ì„±ëŠ¥ ëª¨ë¸ (F1 ì ìˆ˜, ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼): {best_reliable_model}\n")
                f.write(f"   - F1: {reliable_models.loc[best_reliable_model, 'mean_f1_score']:.3f}\n")
                f.write(f"   - Precision: {reliable_models.loc[best_reliable_model, 'mean_precision']:.3f}\n")
                f.write(f"   - Recall: {reliable_models.loc[best_reliable_model, 'mean_recall']:.3f}\n")
                f.write(f"   - í…ŒìŠ¤íŠ¸ ìˆ˜: {int(reliable_models.loc[best_reliable_model, 'count_confidence_score'])}ê°œ\n\n")

            # ì „ì²´ 1ìœ„ (í…ŒìŠ¤íŠ¸ ìˆ˜ ë¬´ê´€)
            best_model_overall = model_stats.index[0]
            best_model_test_count = int(model_stats.loc[best_model_overall, 'count_confidence_score'])
            if best_model_test_count < min_tests and not reliable_models.empty:
                f.write(f"âš ï¸  ì°¸ê³ : ì „ì²´ 1ìœ„ëŠ” {best_model_overall} (F1: {model_stats.loc[best_model_overall, 'mean_f1_score']:.3f})ì´ì§€ë§Œ,\n")
                f.write(f"    í…ŒìŠ¤íŠ¸ ìˆ˜ê°€ {best_model_test_count}ê°œë¡œ ë¶€ì¡±í•˜ì—¬ í†µê³„ì  ì‹ ë¢°ë„ê°€ ë‚®ìŠµë‹ˆë‹¤.\n\n")

            fastest_model = response_stats.index[0]
            best_detector = vuln_by_model.index[0]

            f.write(f"âš¡ ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸: {fastest_model} ({response_stats.loc[fastest_model, 'mean']:.2f}ì´ˆ)\n")
            f.write(f"ğŸ” ìµœë‹¤ íƒì§€ ëª¨ë¸: {best_detector} (í‰ê·  {vuln_by_model.loc[best_detector, 'mean']:.1f}ê°œ)\n")
            f.write(f"ğŸ¯ ìµœê³  ì„±ëŠ¥ ì—ì´ì „íŠ¸: {agent_stats.index[agent_stats['mean_confidence_score'].argmax()]} ")
            f.write(f"(ì‹ ë¢°ë„ {agent_stats['mean_confidence_score'].max():.3f})\n\n")

            f.write("ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ.\n")

        print(f"ğŸ“„ ë¶„ì„ ë¦¬í¬íŠ¸ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def create_visualizations(self) -> None:
        """ì‹œê°í™” ìƒì„±"""
        if self.df.empty:
            print("âŒ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')
        # macOSì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•œ í°íŠ¸ ì„¤ì •
        plt.rcParams['font.family'] = ['AppleGothic', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False  # ë§ˆì´ë„ˆìŠ¤ ê¸°í˜¸ ê¹¨ì§ ë°©ì§€

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('AI Benchmark Results Analysis', fontsize=16)

        # 1. Model Performance Comparison
        model_performance = self.df.groupby('provider_model')['confidence_score'].mean().sort_values(ascending=True)
        axes[0, 0].barh(range(len(model_performance)), model_performance.values)
        axes[0, 0].set_yticks(range(len(model_performance)))
        axes[0, 0].set_yticklabels(model_performance.index)
        axes[0, 0].set_xlabel('Average Confidence Score')
        axes[0, 0].set_title('Model Performance Comparison')

        # 2. Response Time Distribution
        self.df.boxplot(column='response_time', by='provider_model', ax=axes[0, 1])
        axes[0, 1].set_xlabel('Model')
        axes[0, 1].set_ylabel('Response Time (s)')
        axes[0, 1].set_title('Response Time Distribution by Model')
        axes[0, 1].tick_params(axis='x', rotation=45)

        # 3. Agent Performance
        agent_performance = self.df.groupby('agent_type')['confidence_score'].mean()
        axes[1, 0].bar(range(len(agent_performance)), agent_performance.values)
        axes[1, 0].set_xticks(range(len(agent_performance)))
        axes[1, 0].set_xticklabels(agent_performance.index, rotation=45)
        axes[1, 0].set_ylabel('Average Confidence Score')
        axes[1, 0].set_title('Agent Performance')

        # 4. Quantum-Vulnerable Detection vs Confidence
        if 'detected_quantum_vulnerable_count' in self.df.columns:
            axes[1, 1].scatter(self.df['detected_quantum_vulnerable_count'], self.df['confidence_score'], alpha=0.6)
            axes[1, 1].set_xlabel('Detected Quantum-Vulnerable Algorithms')
            axes[1, 1].set_ylabel('Confidence Score')
            axes[1, 1].set_title('Detection Count vs Confidence')

        plt.tight_layout()
        plt.savefig('benchmark_analysis.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š ì‹œê°í™”ê°€ benchmark_analysis.pngì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    parser = argparse.ArgumentParser(description='ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„')
    parser.add_argument('results_file', help='ë¶„ì„í•  ê²°ê³¼ íŒŒì¼')
    parser.add_argument('--compare-models', action='store_true', help='ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ')
    parser.add_argument('--compare-agents', action='store_true', help='ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¹„êµ')
    parser.add_argument('--quantum-vulnerable-analysis', action='store_true', help='ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„')
    parser.add_argument('--performance-analysis', action='store_true', help='ì„±ëŠ¥ ë¶„ì„')
    parser.add_argument('--correlation', action='store_true', help='ìƒê´€ê´€ê³„ ë¶„ì„')
    parser.add_argument('--visualize', action='store_true', help='ì‹œê°í™” ìƒì„±')
    parser.add_argument('--report', help='ë¦¬í¬íŠ¸ íŒŒì¼ëª…')
    parser.add_argument('--all', action='store_true', help='ëª¨ë“  ë¶„ì„ ì‹¤í–‰')

    args = parser.parse_args()

    if not Path(args.results_file).exists():
        print(f"âŒ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.results_file}")
        return

    analyzer = ResultAnalyzer(args.results_file)

    if args.all or args.compare_models:
        analyzer.compare_models()

    if args.all or args.compare_agents:
        analyzer.compare_agents()

    if args.all or args.quantum_vulnerable_analysis:
        analyzer.analyze_quantum_vulnerable_algorithms()

    if args.all or args.performance_analysis:
        analyzer.performance_analysis()

    if args.all or args.correlation:
        analyzer.correlation_analysis()

    if args.all or args.visualize:
        try:
            analyzer.create_visualizations()
        except ImportError:
            print("âš ï¸  matplotlibê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    if args.report or args.all:
        analyzer.generate_report(args.report)

if __name__ == "__main__":
    main()