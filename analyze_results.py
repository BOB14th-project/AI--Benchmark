#!/usr/bin/env python3
"""
ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„ ë„êµ¬
ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•©ë‹ˆë‹¤.
"""

import json
import argparse
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import Dict, Any, List
import numpy as np

class ResultAnalyzer:
    def __init__(self, results_file: str):
        self.results_file = results_file
        self.results = self._load_results()
        self.df = self._create_dataframe()

    def _load_results(self) -> Dict[str, Any]:
        """ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
        with open(self.results_file, 'r', encoding='utf-8') as f:
            return json.load(f)

    def _create_dataframe(self) -> pd.DataFrame:
        """ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        detailed_results = self.results.get('detailed_results', [])

        # ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ë§Œ í•„í„°ë§
        successful_results = [r for r in detailed_results if r.get('success', False)]

        if not successful_results:
            print("âŒ ë¶„ì„í•  ì„±ê³µí•œ í…ŒìŠ¤íŠ¸ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return pd.DataFrame()

        df = pd.DataFrame(successful_results)

        # ì¶”ê°€ ê³„ì‚° ì»¬ëŸ¼
        if not df.empty:
            df['provider_model'] = df['provider'] + '/' + df['model']
            df['total_tokens'] = df['usage'].apply(lambda x: x.get('total_tokens', 0) if isinstance(x, dict) else 0)
            df['efficiency'] = df.apply(
                lambda row: row['confidence_score'] / max(row['total_tokens'], 1) * 1000 if row['total_tokens'] > 0 else 0,
                axis=1
            )

        return df

    def compare_models(self) -> None:
        """ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ"""
        print("\n" + "=" * 60)
        print("ğŸ† ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ")
        print("=" * 60)

        if self.df.empty:
            print("âŒ ë¶„ì„í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ëª¨ë¸ë³„ ì§‘ê³„
        model_stats = self.df.groupby('provider_model').agg({
            'confidence_score': ['mean', 'std', 'count'],
            'response_time': ['mean', 'std'],
            'detected_vulnerabilities': ['mean', 'std'],
            'valid_json': 'mean',
            'total_tokens': 'mean',
            'efficiency': 'mean'
        }).round(3)

        # ì»¬ëŸ¼ëª… ì •ë¦¬
        model_stats.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in model_stats.columns]

        # F1 ì ìˆ˜ ê³„ì‚° (ë‹¨ìˆœí™”ëœ ë²„ì „)
        model_stats['f1_score'] = model_stats['mean_confidence_score'] * model_stats['mean_valid_json']

        print("\nğŸ“Š ëª¨ë¸ë³„ ìƒì„¸ í†µê³„:")
        print("-" * 60)

        for model in model_stats.index:
            stats = model_stats.loc[model]
            print(f"\nğŸ¤– {model}:")
            print(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {int(stats['count_confidence_score'])}")
            print(f"  í‰ê·  ì‹ ë¢°ë„: {stats['mean_confidence_score']:.3f} (Â±{stats['std_confidence_score']:.3f})")
            print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {stats['mean_response_time']:.2f}ì´ˆ (Â±{stats['std_response_time']:.2f})")
            print(f"  í‰ê·  ì·¨ì•½ì  íƒì§€: {stats['mean_detected_vulnerabilities']:.1f}ê°œ")
            print(f"  JSON ìœ íš¨ì„±: {stats['mean_valid_json']:.1%}")
            print(f"  í‰ê·  í† í° ì‚¬ìš©: {stats['mean_total_tokens']:.0f}")
            print(f"  íš¨ìœ¨ì„±: {stats['mean_efficiency']:.3f}")
            print(f"  F1 ì ìˆ˜: {stats['f1_score']:.3f}")

        # ìˆœìœ„ ì¶œë ¥
        print(f"\nğŸ¥‡ ëª¨ë¸ ìˆœìœ„ (F1 ì ìˆ˜ ê¸°ì¤€):")
        ranked_models = model_stats.sort_values('f1_score', ascending=False)
        for i, (model, stats) in enumerate(ranked_models.iterrows(), 1):
            print(f"  {i}. {model}: {stats['f1_score']:.3f}")

    def compare_agents(self) -> None:
        """ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¹„êµ"""
        print("\n" + "=" * 60)
        print("ğŸ¯ ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¶„ì„")
        print("=" * 60)

        if self.df.empty:
            return

        agent_stats = self.df.groupby('agent_type').agg({
            'confidence_score': ['mean', 'std', 'count'],
            'response_time': 'mean',
            'detected_vulnerabilities': 'mean',
            'valid_json': 'mean'
        }).round(3)

        agent_stats.columns = [f"{col[1]}_{col[0]}" if col[1] else col[0] for col in agent_stats.columns]

        for agent in agent_stats.index:
            stats = agent_stats.loc[agent]
            print(f"\nğŸ” {agent}:")
            print(f"  í…ŒìŠ¤íŠ¸ ìˆ˜: {int(stats['count_confidence_score'])}")
            print(f"  í‰ê·  ì‹ ë¢°ë„: {stats['mean_confidence_score']:.3f} (Â±{stats['std_confidence_score']:.3f})")
            print(f"  í‰ê·  ì‘ë‹µì‹œê°„: {stats['mean_response_time']:.2f}ì´ˆ")
            print(f"  í‰ê·  ì·¨ì•½ì  íƒì§€: {stats['mean_detected_vulnerabilities']:.1f}ê°œ")
            print(f"  JSON ìœ íš¨ì„±: {stats['mean_valid_json']:.1%}")

    def analyze_vulnerabilities(self) -> None:
        """ì·¨ì•½ì  íƒì§€ ë¶„ì„"""
        print("\n" + "=" * 60)
        print("ğŸ” ì·¨ì•½ì  íƒì§€ ë¶„ì„")
        print("=" * 60)

        if self.df.empty:
            return

        # ì „ì²´ í†µê³„
        total_tests = len(self.df)
        avg_vulnerabilities = self.df['detected_vulnerabilities'].mean()
        max_vulnerabilities = self.df['detected_vulnerabilities'].max()

        print(f"ğŸ“Š ì „ì²´ í†µê³„:")
        print(f"  ì´ í…ŒìŠ¤íŠ¸: {total_tests}")
        print(f"  í‰ê·  ì·¨ì•½ì  íƒì§€: {avg_vulnerabilities:.1f}ê°œ")
        print(f"  ìµœëŒ€ ì·¨ì•½ì  íƒì§€: {int(max_vulnerabilities)}ê°œ")

        # ëª¨ë¸ë³„ ì·¨ì•½ì  íƒì§€ ëŠ¥ë ¥
        vuln_by_model = self.df.groupby('provider_model')['detected_vulnerabilities'].agg(['mean', 'max', 'count'])
        vuln_by_model = vuln_by_model.sort_values('mean', ascending=False)

        print(f"\nğŸ¯ ëª¨ë¸ë³„ ì·¨ì•½ì  íƒì§€ ëŠ¥ë ¥:")
        for model, stats in vuln_by_model.iterrows():
            print(f"  {model}: í‰ê·  {stats['mean']:.1f}ê°œ, ìµœëŒ€ {int(stats['max'])}ê°œ ({int(stats['count'])}ê°œ í…ŒìŠ¤íŠ¸)")

        # ì—ì´ì „íŠ¸ë³„ ì·¨ì•½ì  íƒì§€
        vuln_by_agent = self.df.groupby('agent_type')['detected_vulnerabilities'].agg(['mean', 'max'])
        vuln_by_agent = vuln_by_agent.sort_values('mean', ascending=False)

        print(f"\nğŸ” ì—ì´ì „íŠ¸ë³„ ì·¨ì•½ì  íƒì§€:")
        for agent, stats in vuln_by_agent.iterrows():
            print(f"  {agent}: í‰ê·  {stats['mean']:.1f}ê°œ, ìµœëŒ€ {int(stats['max'])}ê°œ")

    def performance_analysis(self) -> None:
        """ì„±ëŠ¥ ë¶„ì„"""
        print("\n" + "=" * 60)
        print("âš¡ ì„±ëŠ¥ ë¶„ì„")
        print("=" * 60)

        if self.df.empty:
            return

        # ì‘ë‹µ ì‹œê°„ ë¶„ì„
        response_stats = self.df.groupby('provider_model')['response_time'].agg(['mean', 'min', 'max', 'std'])
        response_stats = response_stats.sort_values('mean')

        print(f"ğŸ“ˆ ì‘ë‹µ ì‹œê°„ ë¶„ì„ (ì´ˆ):")
        for model, stats in response_stats.iterrows():
            print(f"  {model}: {stats['mean']:.2f}s (Â±{stats['std']:.2f}s, ë²”ìœ„: {stats['min']:.2f}s-{stats['max']:.2f}s)")

        # í† í° íš¨ìœ¨ì„±
        if 'total_tokens' in self.df.columns:
            token_stats = self.df.groupby('provider_model')['total_tokens'].agg(['mean', 'std'])
            efficiency_stats = self.df.groupby('provider_model')['efficiency'].agg(['mean', 'std'])

            print(f"\nğŸ’° í† í° ì‚¬ìš©ëŸ‰ ë° íš¨ìœ¨ì„±:")
            for model in token_stats.index:
                token_mean = token_stats.loc[model, 'mean']
                token_std = token_stats.loc[model, 'std']
                eff_mean = efficiency_stats.loc[model, 'mean']
                print(f"  {model}: {token_mean:.0f} í† í° (Â±{token_std:.0f}), íš¨ìœ¨ì„±: {eff_mean:.3f}")

    def correlation_analysis(self) -> None:
        """ìƒê´€ê´€ê³„ ë¶„ì„"""
        print("\n" + "=" * 60)
        print("ğŸ”— ìƒê´€ê´€ê³„ ë¶„ì„")
        print("=" * 60)

        if self.df.empty or len(self.df) < 10:
            print("âŒ ìƒê´€ê´€ê³„ ë¶„ì„ì— ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ë§Œ ì„ íƒ
        numeric_cols = ['confidence_score', 'response_time', 'detected_vulnerabilities', 'total_tokens']
        available_cols = [col for col in numeric_cols if col in self.df.columns]

        if len(available_cols) < 2:
            print("âŒ ìƒê´€ê´€ê³„ ë¶„ì„ì— ì¶©ë¶„í•œ ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return

        correlation_matrix = self.df[available_cols].corr()

        print("ğŸ“Š ìƒê´€ê´€ê³„ ë§¤íŠ¸ë¦­ìŠ¤:")
        print(correlation_matrix.round(3))

        # ì£¼ìš” ìƒê´€ê´€ê³„ í•´ì„
        print("\nğŸ” ì£¼ìš” ë°œê²¬ì‚¬í•­:")
        if 'confidence_score' in available_cols and 'detected_vulnerabilities' in available_cols:
            corr_conf_vuln = correlation_matrix.loc['confidence_score', 'detected_vulnerabilities']
            print(f"  ì‹ ë¢°ë„ vs ì·¨ì•½ì  íƒì§€: {corr_conf_vuln:.3f}")

        if 'response_time' in available_cols and 'confidence_score' in available_cols:
            corr_time_conf = correlation_matrix.loc['response_time', 'confidence_score']
            print(f"  ì‘ë‹µì‹œê°„ vs ì‹ ë¢°ë„: {corr_time_conf:.3f}")

    def generate_report(self, output_file: str = None) -> None:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        if output_file is None:
            output_file = f"analysis_report_{int(self.results['metadata']['timestamp'])}.txt"

        with open(output_file, 'w', encoding='utf-8') as f:
            # ê¸°ë³¸ ì •ë³´ ì €ì¥
            f.write("AI ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„ ë¦¬í¬íŠ¸\n")
            f.write("=" * 60 + "\n\n")

            metadata = self.results.get('metadata', {})
            f.write(f"ì‹¤í–‰ ì‹œê°„: {metadata.get('timestamp', 'Unknown')}\n")
            f.write(f"ì´ í…ŒìŠ¤íŠ¸: {metadata.get('total_tests', 'Unknown')}\n")
            f.write(f"í”„ë¡œë°”ì´ë”: {', '.join(metadata.get('providers', []))}\n")
            f.write(f"ì—ì´ì „íŠ¸: {', '.join(metadata.get('agents', []))}\n\n")

            # ìš”ì•½ í†µê³„ ì €ì¥
            summary = self.results.get('summary', {})
            f.write(f"ì„±ê³µë¥ : {summary.get('success_rate', 0):.1%}\n")
            f.write(f"ì„±ê³µí•œ í…ŒìŠ¤íŠ¸: {summary.get('successful_tests', 0)}\n\n")

        print(f"ğŸ“„ ë¶„ì„ ë¦¬í¬íŠ¸ê°€ {output_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    def create_visualizations(self) -> None:
        """ì‹œê°í™” ìƒì„±"""
        if self.df.empty:
            print("âŒ ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("\nğŸ“Š ì‹œê°í™” ìƒì„± ì¤‘...")

        # ìŠ¤íƒ€ì¼ ì„¤ì •
        plt.style.use('seaborn-v0_8' if 'seaborn-v0_8' in plt.style.available else 'default')
        plt.rcParams['font.family'] = ['DejaVu Sans', 'Malgun Gothic', 'Apple Gothic']

        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('AI ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„', fontsize=16)

        # 1. ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ
        model_performance = self.df.groupby('provider_model')['confidence_score'].mean().sort_values(ascending=True)
        axes[0, 0].barh(range(len(model_performance)), model_performance.values)
        axes[0, 0].set_yticks(range(len(model_performance)))
        axes[0, 0].set_yticklabels(model_performance.index)
        axes[0, 0].set_xlabel('í‰ê·  ì‹ ë¢°ë„ ì ìˆ˜')
        axes[0, 0].set_title('ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ')

        # 2. ì‘ë‹µ ì‹œê°„ ë¶„í¬
        self.df.boxplot(column='response_time', by='provider_model', ax=axes[0, 1])
        axes[0, 1].set_xlabel('ëª¨ë¸')
        axes[0, 1].set_ylabel('ì‘ë‹µ ì‹œê°„ (ì´ˆ)')
        axes[0, 1].set_title('ëª¨ë¸ë³„ ì‘ë‹µ ì‹œê°„ ë¶„í¬')
        axes[0, 1].tick_params(axis='x', rotation=45)

        # 3. ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥
        agent_performance = self.df.groupby('agent_type')['confidence_score'].mean()
        axes[1, 0].bar(range(len(agent_performance)), agent_performance.values)
        axes[1, 0].set_xticks(range(len(agent_performance)))
        axes[1, 0].set_xticklabels(agent_performance.index, rotation=45)
        axes[1, 0].set_ylabel('í‰ê·  ì‹ ë¢°ë„ ì ìˆ˜')
        axes[1, 0].set_title('ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥')

        # 4. ì·¨ì•½ì  íƒì§€ vs ì‹ ë¢°ë„
        if 'detected_vulnerabilities' in self.df.columns:
            axes[1, 1].scatter(self.df['detected_vulnerabilities'], self.df['confidence_score'], alpha=0.6)
            axes[1, 1].set_xlabel('íƒì§€ëœ ì·¨ì•½ì  ìˆ˜')
            axes[1, 1].set_ylabel('ì‹ ë¢°ë„ ì ìˆ˜')
            axes[1, 1].set_title('ì·¨ì•½ì  íƒì§€ vs ì‹ ë¢°ë„')

        plt.tight_layout()
        plt.savefig('benchmark_analysis.png', dpi=300, bbox_inches='tight')
        print("ğŸ“Š ì‹œê°í™”ê°€ benchmark_analysis.pngì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

def main():
    parser = argparse.ArgumentParser(description='ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„')
    parser.add_argument('results_file', help='ë¶„ì„í•  ê²°ê³¼ íŒŒì¼')
    parser.add_argument('--compare-models', action='store_true', help='ëª¨ë¸ë³„ ì„±ëŠ¥ ë¹„êµ')
    parser.add_argument('--compare-agents', action='store_true', help='ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¹„êµ')
    parser.add_argument('--vulnerability-analysis', action='store_true', help='ì·¨ì•½ì  íƒì§€ ë¶„ì„')
    parser.add_argument('--performance-analysis', action='store_true', help='ì„±ëŠ¥ ë¶„ì„')
    parser.add_argument('--correlation', action='store_true', help='ìƒê´€ê´€ê³„ ë¶„ì„')
    parser.add_argument('--visualize', action='store_true', help='ì‹œê°í™” ìƒì„±')
    parser.add_argument('--report', help='ë¦¬í¬íŠ¸ íŒŒì¼ëª…')
    parser.add_argument('--all', action='store_true', help='ëª¨ë“  ë¶„ì„ ì‹¤í–‰')

    args = parser.parse_args()

    if not Path(args.results_file).exists():
        print(f"âŒ ê²°ê³¼ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.results_file}")
        return

    analyzer = ResultAnalyzer(args.results_file)

    if args.all or args.compare_models:
        analyzer.compare_models()

    if args.all or args.compare_agents:
        analyzer.compare_agents()

    if args.all or args.vulnerability_analysis:
        analyzer.analyze_vulnerabilities()

    if args.all or args.performance_analysis:
        analyzer.performance_analysis()

    if args.all or args.correlation:
        analyzer.correlation_analysis()

    if args.all or args.visualize:
        try:
            analyzer.create_visualizations()
        except ImportError:
            print("âš ï¸  matplotlibê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ ì‹œê°í™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")

    if args.report or args.all:
        analyzer.generate_report(args.report)

if __name__ == "__main__":
    main()