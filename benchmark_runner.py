#!/usr/bin/env python3
"""
í†µí•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì‹œìŠ¤í…œ
ëª¨ë“  ëª¨ë¸ê³¼ ì—ì´ì „íŠ¸ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì„±ëŠ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.
"""

import os
import json
import time
import argparse
import csv
from pathlib import Path
from typing import Dict, Any, List, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

from config.config_loader import ConfigLoader
from clients.client_factory import ClientFactory
from clients.ollama_client import OllamaClient
from agents.agent_factory import AgentFactory
from utils.test_case_manager import TestCaseManager

class BenchmarkRunner:
    def __init__(self, config_path: str = "config/config.yaml"):
        self.config_loader = ConfigLoader(config_path)
        self.test_manager = TestCaseManager(
            test_cases_dir="data/test_cases",
            ground_truth_dir="data/ground_truth",
            test_files_dir="data/test_files"
        )
        self.results = {}
        self.lock = threading.Lock()

    def get_available_models(self) -> Dict[str, List[str]]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ì„ ì¡°íšŒ (configì—ì„œ ë™ì ìœ¼ë¡œ ë¡œë“œ)"""
        models = {}

        # API ê¸°ë°˜ í”„ë¡œë°”ì´ë”ë“¤ (google, openai, xai)
        for provider in ['google', 'openai', 'xai']:
            try:
                provider_config = self.config_loader.get_llm_config(provider)
                model_value = provider_config.get('model')

                # ëª¨ë¸ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
                if isinstance(model_value, list):
                    models[provider] = model_value
                # ëª¨ë¸ì´ ë¬¸ìì—´ì¸ ê²½ìš°
                elif isinstance(model_value, str):
                    models[provider] = [model_value]
                else:
                    models[provider] = []

                if models[provider]:
                    print(f"âœ… {provider} ëª¨ë¸: {models[provider]}")
            except Exception as e:
                models[provider] = []
                print(f"âŒ {provider} ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")

        # Ollama ëª¨ë¸ ê°€ìš©ì„± í™•ì¸
        try:
            # ë¨¼ì € configì—ì„œ ì„¤ì • ì½ê¸°
            ollama_config = self.config_loader.get_llm_config('ollama')
            configured_models = ollama_config.get('model', [])

            if isinstance(configured_models, str):
                configured_models = [configured_models]

            # Base URL ê°€ì ¸ì˜¤ê¸°
            base_url = ollama_config.get('base_url', 'http://localhost:11434')

            # Ollama í´ë¼ì´ì–¸íŠ¸ë¡œ ì„œë²„ ì²´í¬
            ollama_client = OllamaClient(base_url=base_url)
            available_ollama = ollama_client.list_available_models()

            if available_ollama:
                # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë§Œ í•„í„°ë§
                models['ollama'] = [m for m in configured_models if m in available_ollama]
                print(f"âœ… Ollama ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {models['ollama']}")

                if not models['ollama']:
                    print(f"âš ï¸  ì„¤ì •ëœ ëª¨ë¸ {configured_models}ì´ Ollamaì— ì—†ìŠµë‹ˆë‹¤.")
                    print(f"   ì‚¬ìš© ê°€ëŠ¥: {available_ollama}")
            else:
                models['ollama'] = []
                print("âŒ Ollama ì„œë²„ê°€ ì‹¤í–‰ë˜ì§€ ì•Šê±°ë‚˜ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            models['ollama'] = []
            print(f"âŒ Ollama í™•ì¸ ì‹¤íŒ¨: {e}")
            import traceback
            traceback.print_exc()

        return models

    def load_test_files(self, agent_type: str, limit: Optional[int] = None) -> List[Dict[str, Any]]:
        """íŠ¹ì • ì—ì´ì „íŠ¸ íƒ€ì…ì˜ í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤ì„ ë¡œë“œ"""
        test_cases = self.test_manager.load_test_cases(agent_type)

        if limit:
            test_cases = test_cases[:limit]

        print(f"ğŸ“ {agent_type}: {len(test_cases)}ê°œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œë¨")
        return test_cases

    def run_single_test(self, provider: str, model: str, agent_type: str,
                       test_case: Dict[str, Any]) -> Dict[str, Any]:
        """ë‹¨ì¼ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        try:
            print(f"    ğŸ”§ Debug: {provider}/{model} í…ŒìŠ¤íŠ¸ ì‹œì‘")
            # í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            if provider == 'ollama':
                client = ClientFactory.create_client(provider, {
                    'api_key': 'not_required',
                    'model': model,
                    'base_url': 'http://localhost:11434'
                })
            else:
                llm_config = self.config_loader.get_llm_config(provider, model_name=model)
                client = ClientFactory.create_client(provider, llm_config)

            # ì—ì´ì „íŠ¸ ìƒì„±
            print(f"    ğŸ”§ Debug: ì—ì´ì „íŠ¸ ìƒì„± ì¤‘...")
            agent = AgentFactory.create_agent(agent_type)
            print(f"    ğŸ”§ Debug: ì—ì´ì „íŠ¸ ìƒì„± ì™„ë£Œ")

            # ì…ë ¥ ë°ì´í„° ì¤€ë¹„
            input_data = test_case.get('input_data', '')
            if not input_data:
                return {
                    'error': 'No input data',
                    'test_id': test_case.get('test_id', 'unknown')
                }

            # ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ëª¨ë¸ë³„ë¡œ ë‹¤ë¥´ê²Œ ì„¤ì • ê°€ëŠ¥)
            max_length = 4000 if provider == 'ollama' else 6000
            
            if len(input_data) > max_length:
                input_data = input_data[:max_length] + "\n... (truncated for length)"

            # ì…ë ¥ ê²€ì¦
            if not agent.validate_input(input_data):
                return {
                    'error': 'Input validation failed',
                    'test_id': test_case.get('test_id', 'unknown')
                }

            # í”„ë¡¬í”„íŠ¸ ìƒì„±
            prompt = agent.create_prompt(input_data)

            # API í˜¸ì¶œ
            print(f"    ğŸ”§ Debug: API í˜¸ì¶œ ì‹œì‘...")
            max_tokens = 1500 if provider == 'ollama' else 2000
            if 'qwen3' in model:
                max_tokens = 1000  # Qwen3ì€ ë” ì§§ì€ í† í°ìœ¼ë¡œ ì„¤ì •
            response = client.benchmark_request(prompt, max_tokens)
            print(f"    ğŸ”§ Debug: API í˜¸ì¶œ ì™„ë£Œ, success={response.get('success', 'unknown')}")

            if not response['success']:
                print(f"    âš ï¸  API í˜¸ì¶œ ì‹¤íŒ¨ ({provider}/{model}): {response['error']}")
                return {
                    'error': response['error'],
                    'test_id': test_case.get('test_id', 'unknown'),
                    'response_time': response['response_time']
                }

            # ê²°ê³¼ íŒŒì‹±
            print(f"    ğŸ”§ Debug: ê²°ê³¼ íŒŒì‹± ì‹œì‘...")
            findings = agent.extract_key_findings(response['content'])
            print(f"    ğŸ”§ Debug: íŒŒì‹± ì™„ë£Œ, valid_json={findings.get('valid_json', 'unknown')}")
            if not findings.get('valid_json', False) and 'qwen3' in model:
                print(f"    ğŸ”§ Debug Qwen3 ì‘ë‹µ: {response['content'][:500]}...")

            # ì‹¤ì œ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ ìˆ˜ ê³„ì‚°
            print(f"    ğŸ”§ Debug: ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ ì¶”ì¶œ ì‹œì‘...")
            detected_quantum_vulnerable_algorithms = []
            if findings['valid_json']:
                analysis_results = findings['analysis_results']

                # ê° ë¶„ì„ ê²°ê³¼ì—ì„œ ì‹¤ì œ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ ì¶”ì¶œ
                for category, result in analysis_results.items():
                    if result and result.lower() not in ['none', 'not detected', 'no', '', 'not present', 'no implementations']:
                        # ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ ì¶”ì¶œ (ìƒˆë¡œìš´ í˜•ì‹ì— ë§ê²Œ)
                        import re
                        result_lower = result.lower()

                        # "DETECTED:" í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
                        if result_lower.startswith('detected:'):
                            # "DETECTED: RSA" â†’ "RSA" ì¶”ì¶œ
                            detected_algo = result.split(':', 1)[1].strip()
                            detected_quantum_vulnerable_algorithms.append(detected_algo.upper())
                        else:
                            # ê¸°ì¡´ ë°©ì‹ë„ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
                            # ë¶€ì •ì  í‘œí˜„ ì²´í¬
                            negative_indicators = ['does not contain', 'not contain', 'no implementation', 'not found', 'absent', 'missing', 'not present', 'free from', 'not detected']
                            has_negative_indicator = any(indicator in result_lower for indicator in negative_indicators)

                            if has_negative_indicator:
                                continue  # ë¶€ì •ì  ì‘ë‹µì€ ê±´ë„ˆë›°ê¸°

                            # ì£¼ìš” ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ë“¤ ì²´í¬ (ìš°ì„ ìˆœìœ„ ìˆœìœ¼ë¡œ ì •ë ¬)
                            quantum_vulnerable_algos = [
                                # ê¸¸ì´ê°€ ê¸´ ê²ƒë¶€í„° ì²´í¬í•˜ì—¬ ì¤‘ë³µ ë°©ì§€
                                ('diffie-hellman', 'DH'), ('ecdsa', 'ECDSA'), ('ecdh', 'ECDH'),
                                ('aes-128', 'AES-128'), ('3des', '3DES'), ('sha-1', 'SHA-1'),
                                ('has-160', 'HAS-160'), ('kcdsa', 'KCDSA'), ('a5/1', 'A5/1'),
                                ('misty1', 'MISTY1'), ('twofish', 'Twofish'), ('blowfish', 'Blowfish'),
                                ('skipjack', 'Skipjack'), ('elgamal', 'ElGamal'), ('trivium', 'Trivium'),
                                ('whirlpool', 'Whirlpool'), ('tiger', 'Tiger'), ('cast', 'CAST'),
                                ('idea', 'IDEA'), ('rsa', 'RSA'), ('ecc', 'ECC'), ('dsa', 'DSA'),
                                ('dh', 'DH'), ('aes', 'AES'), ('des', 'DES'), ('rc4', 'RC4'),
                                ('md5', 'MD5'), ('sha1', 'SHA-1'), ('seed', 'SEED'), ('aria', 'ARIA'),
                                ('hight', 'HIGHT'), ('lea', 'LEA'), ('lsh', 'LSH'), ('a5', 'A5')
                            ]

                            # ëª…í™•í•œ íƒì§€ í‘œí˜„ì´ ìˆëŠ” ê²½ìš°ë§Œ ì¹´ìš´íŒ…
                            positive_indicators = ['detected', 'found', 'implementation', 'algorithm', 'cipher', 'present', 'identified', 'system', 'used', 'exists', 'contains']
                            has_positive_indicator = any(indicator in result_lower for indicator in positive_indicators)

                            if has_positive_indicator:
                                for algo_pattern, display_name in quantum_vulnerable_algos:
                                    # ì •í™•í•œ ë‹¨ì–´ ë§¤ì¹­ (ê²½ê³„ í¬í•¨)
                                    if re.search(r'\b' + re.escape(algo_pattern) + r'\b', result_lower):
                                        if display_name not in detected_quantum_vulnerable_algorithms:
                                            detected_quantum_vulnerable_algorithms.append(display_name)
                                            break  # ì²« ë²ˆì§¸ ë§¤ì¹˜ë§Œ ì‚¬ìš©

            detected_quantum_vulnerable_count = len(detected_quantum_vulnerable_algorithms)

            # Success í‰ê°€: Ground truthì™€ ë¹„êµí•˜ì—¬ ì •í™•ë„ ê³„ì‚°
            success = False
            accuracy_score = 0.0

            if findings['valid_json']:
                # Ground truth ë¡œë“œ
                ground_truth = self._load_ground_truth(test_case, agent_type)
                if ground_truth:
                    try:
                        from utils.metrics_calculator import MetricsCalculator
                        accuracy_score = MetricsCalculator.calculate_accuracy(findings, ground_truth)
                        print(f"    ğŸ”§ Debug: ì •í™•ë„ ê³„ì‚° ì™„ë£Œ: {accuracy_score:.3f}")
                        # 60% ì´ìƒ ì •í™•ë„ë©´ ì„±ê³µìœ¼ë¡œ ê°„ì£¼
                        success = accuracy_score >= 0.6
                    except Exception as metric_error:
                        print(f"    âŒ ì •í™•ë„ ê³„ì‚° ì‹¤íŒ¨: {metric_error}")
                        accuracy_score = 0.0
                        success = False
                else:
                    # Ground truthê°€ ì—†ìœ¼ë©´ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬ (ì •ë‹µì„ ì•Œ ìˆ˜ ì—†ìœ¼ë¯€ë¡œ)
                    print(f"    âš ï¸  Ground truthê°€ ì—†ì–´ì„œ ì„±ê³µ ì—¬ë¶€ë¥¼ íŒë‹¨í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    success = False
            else:
                success = False

            print(f"    ğŸ”§ Debug: ê²°ê³¼ êµ¬ì„± ì‹œì‘...")
            result = {
                'test_id': test_case.get('test_id', 'unknown'),
                'provider': provider,
                'model': model,
                'agent_type': agent_type,
                'success': success,
                'accuracy_score': accuracy_score,
                'valid_json': findings.get('valid_json', False),
                'confidence_score': findings.get('confidence_score', 0.0),
                'detected_quantum_vulnerable_count': detected_quantum_vulnerable_count,
                'detected_algorithms': detected_quantum_vulnerable_algorithms,
                'response_time': response.get('response_time', 0.0),
                'json_valid': response.get('json_valid', False),
                'summary': findings.get('summary', ''),
                'analysis_results': findings.get('analysis_results', {}),
                'usage': response.get('usage', {}),
                'file_path': test_case.get('file_path', ''),
                'raw_response': findings.get('raw_response', response.get('content', '')),
                'timestamp': time.time()
            }
            print(f"    ğŸ”§ Debug: ê²°ê³¼ êµ¬ì„± ì™„ë£Œ")
            return result

        except Exception as e:
            import traceback
            error_details = f"{str(e)} | Traceback: {traceback.format_exc()}"
            print(f"    âš ï¸  ì˜ˆì™¸ ë°œìƒ ({provider}/{model}): {error_details}")

            return {
                'test_id': test_case.get('test_id', 'unknown'),
                'provider': provider,
                'model': model,
                'agent_type': agent_type,
                'success': False,
                'error': str(e),  # ì‚¬ìš©ìì—ê²ŒëŠ” ê°„ë‹¨í•œ ì—ëŸ¬ë§Œ í‘œì‹œ
                'error_details': error_details,  # ìƒì„¸ ì •ë³´ëŠ” ë³„ë„ í•„ë“œ
                'response_time': 0,
                'timestamp': time.time()
            }

    def run_benchmark(self, providers: List[str] = None, agents: List[str] = None,
                     test_limit: Optional[int] = None, parallel: bool = False) -> Dict[str, Any]:
        """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        print("ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        print("=" * 60)

        # ê¸°ë³¸ê°’ ì„¤ì •
        if providers is None:
            providers = ['ollama', 'google', 'openai', 'xai']
        if agents is None:
            agents = ['source_code', 'assembly_binary', 'logs_config']

        available_models = self.get_available_models()

        # ì—ì´ì „íŠ¸ë³„ë¡œ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ í•œ ë²ˆë§Œ ë¡œë“œ
        agent_test_files = {}
        for agent_type in agents:
            agent_test_files[agent_type] = self.load_test_files(agent_type, test_limit)

        # ì‹¤í–‰í•  í…ŒìŠ¤íŠ¸ ì¡°í•© ìƒì„±
        test_combinations = []
        for provider in providers:
            if provider not in available_models or not available_models[provider]:
                print(f"âš ï¸  {provider} ëª¨ë¸ì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
                continue

            for model in available_models[provider]:
                for agent_type in agents:
                    test_cases = agent_test_files[agent_type]
                    if test_cases:
                        for test_case in test_cases:
                            test_combinations.append((provider, model, agent_type, test_case))

        print(f"ğŸ“Š ì´ {len(test_combinations)}ê°œ í…ŒìŠ¤íŠ¸ ì¡°í•©")

        # ë³‘ë ¬ ë˜ëŠ” ìˆœì°¨ ì‹¤í–‰
        if parallel and len(test_combinations) > 1:
            results = self._run_parallel_tests(test_combinations)
        else:
            results = self._run_sequential_tests(test_combinations)

        # ê²°ê³¼ ì •ë¦¬
        self.results = {
            'summary': self._generate_summary(results),
            'detailed_results': results,
            'metadata': {
                'total_tests': len(test_combinations),
                'timestamp': time.time(),
                'providers': providers,
                'agents': agents,
                'test_limit': test_limit
            }
        }

        return self.results

    def _run_sequential_tests(self, test_combinations: List) -> List[Dict[str, Any]]:
        """ìˆœì°¨ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        results = []
        backup_interval = 10  # 10ê°œ í…ŒìŠ¤íŠ¸ë§ˆë‹¤ ë°±ì—…

        for i, (provider, model, agent_type, test_case) in enumerate(test_combinations, 1):
            print(f"\nğŸ“‹ í…ŒìŠ¤íŠ¸ {i}/{len(test_combinations)}: {provider}/{model}/{agent_type}")
            print(f"    íŒŒì¼: {test_case.get('test_id', 'unknown')}")

            result = self.run_single_test(provider, model, agent_type, test_case)
            results.append(result)

            if result.get('success'):
                print(f"    âœ… ì™„ë£Œ ({result['response_time']:.2f}ì´ˆ)")
                if result['valid_json']:
                    print(f"    ğŸ¯ ì‹ ë¢°ë„: {result['confidence_score']:.3f}")
                    vuln_count = result['detected_quantum_vulnerable_count']
                    if vuln_count > 0:
                        # íƒì§€ëœ ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ë“¤ í‘œì‹œ
                        detected_algos = result.get('detected_algorithms', [])
                        if detected_algos:
                            algos_str = ', '.join(detected_algos[:4])  # ìµœëŒ€ 3ê°œë§Œ í‘œì‹œ
                            if len(detected_algos) > 3:
                                algos_str += f" ì™¸ {len(detected_algos)-3}ê°œ"
                            print(f"    ğŸ” íƒì§€ëœ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜: {algos_str}")
                        else:
                            print(f"    ğŸ” ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜: {vuln_count}ê°œ")
                    else:
                        print(f"    ğŸ” ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜: ì—†ìŒ")
            else:
                if 'accuracy_score' in result:
                    print(f"    âŒ ì‹¤íŒ¨: ì •í™•ë„ {result['accuracy_score']:.1%} < 60% ì„ê³„ê°’")
                else:
                    print(f"    âŒ ì‹¤íŒ¨: {result.get('error', 'Unknown error')}")

            # ì£¼ê¸°ì  ë°±ì—… (Google Drive)
            if i % backup_interval == 0:
                self._backup_intermediate_results(results, i, len(test_combinations))

            # API ì œí•œ ë°©ì§€ë¥¼ ìœ„í•œ ë”œë ˆì´
            if provider != 'ollama' and i < len(test_combinations):
                time.sleep(1)

        return results

    def _backup_intermediate_results(self, results: List[Dict[str, Any]], current: int, total: int):
        """ì¤‘ê°„ ê²°ê³¼ ë°±ì—… (Google Drive)"""
        gdrive_dir = os.environ.get('GDRIVE_RESULTS_DIR')
        if not gdrive_dir or not os.path.exists(gdrive_dir):
            return

        try:
            timestamp = int(time.time())
            backup_filename = f"backup_progress_{current}of{total}_{timestamp}.json"
            backup_path = os.path.join(gdrive_dir, backup_filename)

            backup_data = {
                'progress': f"{current}/{total}",
                'timestamp': timestamp,
                'completed_tests': current,
                'total_tests': total,
                'results': results
            }

            with open(backup_path, 'w', encoding='utf-8') as f:
                json.dump(backup_data, f, indent=2, ensure_ascii=False)

            print(f"    ğŸ’¾ ì¤‘ê°„ ë°±ì—… ì™„ë£Œ: {backup_filename}")
        except Exception as e:
            print(f"    âš ï¸  ì¤‘ê°„ ë°±ì—… ì‹¤íŒ¨: {e}")

    def _run_parallel_tests(self, test_combinations: List) -> List[Dict[str, Any]]:
        """ë³‘ë ¬ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        results = []
        max_workers = 3  # ë™ì‹œ ì‹¤í–‰ ìˆ˜ ì œí•œ

        print(f"ğŸ”„ ë³‘ë ¬ ì²˜ë¦¬ (ìµœëŒ€ {max_workers}ê°œ ë™ì‹œ ì‹¤í–‰)")

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            future_to_test = {}

            for provider, model, agent_type, test_case in test_combinations:
                future = executor.submit(
                    self.run_single_test, provider, model, agent_type, test_case
                )
                future_to_test[future] = (provider, model, agent_type, test_case)

            for i, future in enumerate(as_completed(future_to_test), 1):
                provider, model, agent_type, test_case = future_to_test[future]

                try:
                    result = future.result()
                    results.append(result)

                    print(f"âœ… ì™„ë£Œ {i}/{len(test_combinations)}: {provider}/{model}/{agent_type}")

                except Exception as e:
                    print(f"âŒ ì‹¤íŒ¨ {i}/{len(test_combinations)}: {provider}/{model}/{agent_type} - {e}")
                    results.append({
                        'provider': provider,
                        'model': model,
                        'agent_type': agent_type,
                        'test_id': test_case.get('test_id', 'unknown'),
                        'success': False,
                        'error': str(e)
                    })

        return results

    def _generate_summary(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        total = len(results)
        successful = len([r for r in results if r.get('success', False)])

        summary = {
            'total_tests': total,
            'successful_tests': successful,
            'success_rate': successful / total if total > 0 else 0,
            'by_provider': {},
            'by_agent': {},
            'by_model': {}
        }

        # í”„ë¡œë°”ì´ë”ë³„ í†µê³„
        for result in results:
            provider = result.get('provider', 'unknown')
            agent = result.get('agent_type', 'unknown')
            model = result.get('model', 'unknown')

            # í”„ë¡œë°”ì´ë”ë³„
            if provider not in summary['by_provider']:
                summary['by_provider'][provider] = {
                    'total': 0, 'successful': 0, 'avg_response_time': 0,
                    'avg_confidence': 0, 'avg_quantum_vulnerable': 0
                }

            p_stats = summary['by_provider'][provider]
            p_stats['total'] += 1
            if result.get('success'):
                p_stats['successful'] += 1
                p_stats['avg_response_time'] += result.get('response_time', 0)
                p_stats['avg_confidence'] += result.get('confidence_score', 0)
                p_stats['avg_quantum_vulnerable'] += result.get('detected_quantum_vulnerable_count', 0)

            # ì—ì´ì „íŠ¸ë³„
            if agent not in summary['by_agent']:
                summary['by_agent'][agent] = {'total': 0, 'successful': 0}
            summary['by_agent'][agent]['total'] += 1
            if result.get('success'):
                summary['by_agent'][agent]['successful'] += 1

            # ëª¨ë¸ë³„
            model_key = f"{provider}/{model}"
            if model_key not in summary['by_model']:
                summary['by_model'][model_key] = {'total': 0, 'successful': 0}
            summary['by_model'][model_key]['total'] += 1
            if result.get('success'):
                summary['by_model'][model_key]['successful'] += 1

        # í‰ê·  ê³„ì‚°
        for provider, stats in summary['by_provider'].items():
            if stats['successful'] > 0:
                stats['avg_response_time'] /= stats['successful']
                stats['avg_confidence'] /= stats['successful']
                stats['avg_quantum_vulnerable'] /= stats['successful']
                stats['success_rate'] = stats['successful'] / stats['total']

        return summary

    def save_results(self, filename: str = None) -> str:
        """ê²°ê³¼ë¥¼ JSONê³¼ CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        if filename is None:
            timestamp = int(time.time())
            json_filename = f"benchmark_results_{timestamp}.json"
            csv_filename = f"benchmark_results_{timestamp}.csv"
        else:
            base_name = filename.rsplit('.', 1)[0]
            json_filename = f"{base_name}.json"
            csv_filename = f"{base_name}.csv"

        results_dir = Path("results")
        results_dir.mkdir(exist_ok=True)

        # JSON ì €ì¥
        json_filepath = Path(json_filename)
        with open(json_filepath, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)

        # CSV ì €ì¥
        csv_filepath = Path(csv_filename)
        self._save_csv_results(csv_filepath)

        print(f"ğŸ’¾ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤:")
        print(f"   JSON: {json_filepath}")
        print(f"   CSV: {csv_filepath}")

        # Google Drive ìë™ ë°±ì—… (í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ëœ ê²½ìš°)
        gdrive_dir = os.environ.get('GDRIVE_RESULTS_DIR')
        if gdrive_dir and os.path.exists(gdrive_dir):
            try:
                import shutil
                gdrive_json = os.path.join(gdrive_dir, json_filename)
                gdrive_csv = os.path.join(gdrive_dir, csv_filename)

                shutil.copy2(json_filepath, gdrive_json)
                shutil.copy2(csv_filepath, gdrive_csv)

                print(f"â˜ï¸  Google Drive ë°±ì—… ì™„ë£Œ:")
                print(f"   JSON: {gdrive_json}")
                print(f"   CSV: {gdrive_csv}")
            except Exception as e:
                print(f"âš ï¸  Google Drive ë°±ì—… ì‹¤íŒ¨: {e}")

        return str(json_filepath)

    def _save_csv_results(self, filepath: Path):
        """ê²°ê³¼ë¥¼ CSV í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        detailed_results = self.results.get('detailed_results', [])

        if not detailed_results:
            print("âŒ CSVë¡œ ì €ì¥í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # CSV í—¤ë” ì •ì˜
        fieldnames = [
            'test_id', 'provider', 'model', 'agent_type', 'success',
            'valid_json', 'confidence_score', 'detected_quantum_vulnerable_count',
            'response_time', 'json_valid', 'summary', 'file_path',
            'total_tokens', 'prompt_tokens', 'completion_tokens',
            'timestamp', 'error'
        ]

        with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()

            for result in detailed_results:
                # ê¸°ë³¸ ë°ì´í„° ì¶”ì¶œ
                csv_row = {
                    'test_id': result.get('test_id', ''),
                    'provider': result.get('provider', ''),
                    'model': result.get('model', ''),
                    'agent_type': result.get('agent_type', ''),
                    'success': result.get('success', False),
                    'valid_json': result.get('valid_json', False),
                    'confidence_score': result.get('confidence_score', 0),
                    'detected_quantum_vulnerable_count': result.get('detected_quantum_vulnerable_count', 0),
                    'response_time': result.get('response_time', 0),
                    'json_valid': result.get('json_valid', False),
                    'summary': result.get('summary', '').replace('\n', ' ').replace('\r', ' '),
                    'file_path': result.get('file_path', ''),
                    'timestamp': result.get('timestamp', 0),
                    'error': result.get('error', '')
                }

                # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
                usage = result.get('usage', {})
                if isinstance(usage, dict):
                    csv_row['total_tokens'] = usage.get('total_tokens', 0)
                    csv_row['prompt_tokens'] = usage.get('prompt_tokens', 0)
                    csv_row['completion_tokens'] = usage.get('completion_tokens', 0)
                else:
                    csv_row['total_tokens'] = 0
                    csv_row['prompt_tokens'] = 0
                    csv_row['completion_tokens'] = 0

                writer.writerow(csv_row)

    def print_summary(self):
        """ìš”ì•½ ê²°ê³¼ ì¶œë ¥"""
        if not self.results:
            print("âŒ ì‹¤í–‰ëœ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        summary = self.results['summary']

        print("\n" + "=" * 60)
        print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)

        print(f"ì „ì²´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}")
        print(f"ì„±ê³µ: {summary['successful_tests']}")
        print(f"ì„±ê³µë¥ : {summary['success_rate']:.1%}")

        print(f"\nğŸ† ëª¨ë¸ë³„ ì„±ëŠ¥:")
        for model, stats in summary['by_model'].items():
            print(f"  {model}:")
            print(f"    ì„±ê³µë¥ : {stats.get('success_rate', 0):.1%}")
            print(f"    í‰ê·  ì‘ë‹µì‹œê°„: {stats.get('avg_response_time', 0):.2f}ì´ˆ")
            print(f"    í‰ê·  ì‹ ë¢°ë„: {stats.get('avg_confidence', 0):.3f}")
            print(f"    í‰ê·  ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ íƒì§€: {stats.get('avg_quantum_vulnerable', 0):.1f}ê°œ")

        print(f"\nğŸ¯ ì—ì´ì „íŠ¸ë³„ ì„±ê³µë¥ :")
        for agent, stats in summary['by_agent'].items():
            success_rate = stats['successful'] / stats['total'] if stats['total'] > 0 else 0
            print(f"  {agent}: {success_rate:.1%} ({stats['successful']}/{stats['total']})")

    def _load_ground_truth(self, test_case: Dict[str, Any], agent_type: str = None) -> Dict[str, Any]:
        """í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ì— ëŒ€í•œ ground truth ë¡œë“œ"""
        try:
            test_id = test_case.get('test_id', '')
            # agent_type ë§¤ê°œë³€ìˆ˜ê°€ ì „ë‹¬ë˜ë©´ ì‚¬ìš©, ì•„ë‹ˆë©´ test_caseì—ì„œ ì¶”ì¶œ
            if agent_type is None:
                agent_type = test_case.get('type', 'source_code')

            # Ground truth íŒŒì¼ ê²½ë¡œ ìƒì„±
            ground_truth_path = f"data/ground_truth/{agent_type}/{test_id}.json"

            print(f"    ğŸ”§ Debug: Ground truth ê²½ë¡œ ì‹œë„: {ground_truth_path}")

            if os.path.exists(ground_truth_path):
                with open(ground_truth_path, 'r', encoding='utf-8') as f:
                    ground_truth = json.load(f)
                    print(f"    ğŸ”§ Debug: Ground truth ë¡œë“œ ì„±ê³µ: {ground_truth}")
                    return ground_truth
            else:
                print(f"    âš ï¸  Ground truth íŒŒì¼ ì—†ìŒ: {ground_truth_path}")
        except Exception as e:
            print(f"    âŒ Ground truth ë¡œë“œ ì‹¤íŒ¨: {e}")

        return None

def main():
    parser = argparse.ArgumentParser(description='AI ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰')
    parser.add_argument('--providers', nargs='+',
                       choices=['google', 'openai', 'xai', 'ollama'],
                       help='í…ŒìŠ¤íŠ¸í•  í”„ë¡œë°”ì´ë”ë“¤')
    parser.add_argument('--agents', nargs='+',
                       choices=['source_code', 'assembly_binary', 'logs_config'],
                       help='í…ŒìŠ¤íŠ¸í•  ì—ì´ì „íŠ¸ë“¤')
    parser.add_argument('--limit', type=int, help='ì—ì´ì „íŠ¸ë‹¹ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìˆ˜ ì œí•œ')
    parser.add_argument('--parallel', action='store_true', help='ë³‘ë ¬ ì‹¤í–‰')
    parser.add_argument('--output', help='ê²°ê³¼ íŒŒì¼ëª…')

    args = parser.parse_args()

    runner = BenchmarkRunner()

    try:
        runner.run_benchmark(
            providers=args.providers,
            agents=args.agents,
            test_limit=args.limit,
            parallel=args.parallel
        )

        runner.print_summary()
        runner.save_results(args.output)

    except KeyboardInterrupt:
        print("\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()