#!/usr/bin/env python3
"""
ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
ê° ì»´í¬ë„ŒíŠ¸ê°€ ì˜¬ë°”ë¥´ê²Œ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
"""

import os
import json
from pathlib import Path
from config.config_loader import ConfigLoader
from clients.client_factory import ClientFactory
from clients.ollama_client import OllamaClient
from agents.agent_factory import AgentFactory
from benchmark_runner import BenchmarkRunner

def test_config_loader():
    """ì„¤ì • ë¡œë” í…ŒìŠ¤íŠ¸"""
    print("ğŸ”§ ì„¤ì • ë¡œë” í…ŒìŠ¤íŠ¸...")
    try:
        config_loader = ConfigLoader('config/config.yaml')

        # ê° í”„ë¡œë°”ì´ë” ì„¤ì • í™•ì¸
        providers = ['google', 'openai', 'xai']
        for provider in providers:
            config = config_loader.get_llm_config(provider)
            if config.get('api_key') and config['api_key'] != f"your_{provider}_api_key_here":
                print(f"  âœ… {provider} ì„¤ì • ì™„ë£Œ")
            else:
                print(f"  âš ï¸  {provider} API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")

        print("  âœ… ì„¤ì • ë¡œë” ì •ìƒ ì‘ë™")
        return True
    except Exception as e:
        print(f"  âŒ ì„¤ì • ë¡œë” ì˜¤ë¥˜: {e}")
        return False

def test_ollama_connection():
    """Ollama ì—°ê²° í…ŒìŠ¤íŠ¸"""
    print("\nğŸ¤– Ollama ì—°ê²° í…ŒìŠ¤íŠ¸...")
    try:
        client = OllamaClient()

        if client.is_available():
            models = client.list_available_models()
            print(f"  âœ… Ollama ì„œë²„ ì—°ê²°ë¨")
            print(f"  ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {models}")

            # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸
            if models:
                test_model = models[0]
                test_client = OllamaClient(model=test_model)
                response = test_client.make_request("Hello", max_tokens=10)
                print(f"  âœ… {test_model} í…ŒìŠ¤íŠ¸ ì„±ê³µ")
                return True
            else:
                print("  âš ï¸  ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
        else:
            print("  âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("  ğŸ’¡ ollama serveë¥¼ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            return False
    except Exception as e:
        print(f"  âŒ Ollama í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return False

def test_agents():
    """ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸"""
    print("\nğŸ¯ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸...")
    try:
        agent_types = ['source_code', 'assembly_binary', 'dynamic_analysis', 'logs_config']

        for agent_type in agent_types:
            agent = AgentFactory.create_agent(agent_type)

            # ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
            analysis_points = agent.get_analysis_points()
            test_input = "test input"

            if len(analysis_points) > 0:
                print(f"  âœ… {agent_type}: {len(analysis_points)}ê°œ ë¶„ì„ í¬ì¸íŠ¸")
            else:
                print(f"  âŒ {agent_type}: ë¶„ì„ í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")

        print("  âœ… ëª¨ë“  ì—ì´ì „íŠ¸ ì •ìƒ ì‘ë™")
        return True
    except Exception as e:
        print(f"  âŒ ì—ì´ì „íŠ¸ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        return False

def test_test_files():
    """í…ŒìŠ¤íŠ¸ íŒŒì¼ ì¡´ì¬ í™•ì¸"""
    print("\nğŸ“ í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸...")

    base_dir = Path("data/test_files")
    agent_dirs = ['source_code', 'assembly_binary', 'dynamic_analysis', 'logs_config']

    total_files = 0
    for agent_dir in agent_dirs:
        dir_path = base_dir / agent_dir
        if dir_path.exists():
            files = list(dir_path.glob("*"))
            file_count = len([f for f in files if f.is_file()])
            total_files += file_count
            print(f"  ğŸ“‚ {agent_dir}: {file_count}ê°œ íŒŒì¼")
        else:
            print(f"  âŒ {agent_dir}: ë””ë ‰í† ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")

    if total_files > 0:
        print(f"  âœ… ì´ {total_files}ê°œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë°œê²¬")
        return True
    else:
        print("  âŒ í…ŒìŠ¤íŠ¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

def test_single_benchmark():
    """ë‹¨ì¼ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸"""
    print("\nğŸš€ ë‹¨ì¼ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸...")

    try:
        runner = BenchmarkRunner()

        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸
        available_models = runner.get_available_models()

        # ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë¡œ í…ŒìŠ¤íŠ¸
        test_provider = None
        test_model = None

        for provider, models in available_models.items():
            if models:
                test_provider = provider
                test_model = models[0]
                break

        if not test_provider:
            print("  âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return False

        print(f"  ğŸ¯ í…ŒìŠ¤íŠ¸ ëª¨ë¸: {test_provider}/{test_model}")

        # ì‘ì€ ë²”ìœ„ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        results = runner.run_benchmark(
            providers=[test_provider],
            agents=['source_code'],  # í•˜ë‚˜ì˜ ì—ì´ì „íŠ¸ë§Œ
            test_limit=1,  # íŒŒì¼ í•˜ë‚˜ë§Œ
            parallel=False
        )

        if results and results.get('summary', {}).get('total_tests', 0) > 0:
            print("  âœ… ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì„±ê³µ")

            # ê°„ë‹¨í•œ ê²°ê³¼ ì¶œë ¥
            summary = results['summary']
            print(f"    ì´ í…ŒìŠ¤íŠ¸: {summary['total_tests']}")
            print(f"    ì„±ê³µ: {summary['successful_tests']}")
            print(f"    ì„±ê³µë¥ : {summary['success_rate']:.1%}")

            return True
        else:
            print("  âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False

    except Exception as e:
        print(f"  âŒ ë²¤ì¹˜ë§ˆí¬ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸ§ª AI ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    tests = [
        ("ì„¤ì • ë¡œë”", test_config_loader),
        ("Ollama ì—°ê²°", test_ollama_connection),
        ("ì—ì´ì „íŠ¸", test_agents),
        ("í…ŒìŠ¤íŠ¸ íŒŒì¼", test_test_files),
        ("ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰", test_single_benchmark)
    ]

    results = {}

    for test_name, test_func in tests:
        results[test_name] = test_func()

    # ìµœì¢… ê²°ê³¼
    print("\n" + "=" * 60)
    print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print("=" * 60)

    passed = sum(results.values())
    total = len(results)

    for test_name, result in results.items():
        status = "âœ… í†µê³¼" if result else "âŒ ì‹¤íŒ¨"
        print(f"  {test_name}: {status}")

    print(f"\nì „ì²´ ê²°ê³¼: {passed}/{total} í…ŒìŠ¤íŠ¸ í†µê³¼ ({passed/total:.1%})")

    if passed == total:
        print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼! ì‹œìŠ¤í…œì´ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.")
        print("\nğŸ’¡ ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì „ì²´ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:")
        print("   python benchmark_runner.py --limit 3")
    else:
        print("\nâš ï¸  ì¼ë¶€ í…ŒìŠ¤íŠ¸ê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

        if not results.get("ì„¤ì • ë¡œë”"):
            print("\nğŸ”§ API í‚¤ ì„¤ì • ë°©ë²•:")
            print("   config/config.yaml íŒŒì¼ì—ì„œ API í‚¤ë“¤ì„ ì„¤ì •í•˜ì„¸ìš”.")

        if not results.get("Ollama ì—°ê²°"):
            print("\nğŸ¤– Ollama ì„¤ì • ë°©ë²•:")
            print("   1. ollama serve")
            print("   2. ollama pull deepseek-r1:8b")
            print("   3. ollama pull gemma3:12b")

        if not results.get("í…ŒìŠ¤íŠ¸ íŒŒì¼"):
            print("\nğŸ“ í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸:")
            print("   data/test_files/ ë””ë ‰í† ë¦¬ì— í…ŒìŠ¤íŠ¸ íŒŒì¼ë“¤ì´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    main()