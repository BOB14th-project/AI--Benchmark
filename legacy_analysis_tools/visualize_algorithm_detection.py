#!/usr/bin/env python3
"""
ì•Œê³ ë¦¬ì¦˜ë³„ íƒì§€ ì„±ê³µ/ì‹¤íŒ¨ ì‹œê°í™” ë„êµ¬
"""

import json
import os
import glob
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
import seaborn as sns
import numpy as np
from collections import defaultdict
import argparse

# í•œê¸€ í°íŠ¸ ì„¤ì •
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['axes.unicode_minus'] = False


class AlgorithmDetectionVisualizer:
    def __init__(self, results_file: str = None):
        self.results_file = results_file
        self.results_data = None
        self.ground_truth_cache = {}

    def load_results(self):
        """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ íŒŒì¼ ë¡œë“œ"""
        if not self.results_file:
            result_files = sorted(glob.glob("benchmark_results_*.json"), reverse=True)
            if not result_files:
                print("âŒ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return False
            self.results_file = result_files[0]

        try:
            with open(self.results_file, 'r', encoding='utf-8') as f:
                data = json.load(f)

            # ìƒˆ í˜•ì‹ ì§€ì›: detailed_resultsë¥¼ resultsë¡œ ë³€í™˜
            if 'detailed_results' in data and 'results' not in data:
                data['results'] = data['detailed_results']

            self.results_data = data
            print(f"âœ… ê²°ê³¼ íŒŒì¼ ë¡œë“œ: {self.results_file}\n")
            return True
        except Exception as e:
            print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False

    def load_ground_truth(self, file_name: str, agent_type: str):
        """Ground truth íŒŒì¼ ë¡œë“œ"""
        cache_key = f"{agent_type}/{file_name}"
        if cache_key in self.ground_truth_cache:
            return self.ground_truth_cache[cache_key]

        base_name = os.path.splitext(file_name)[0]
        gt_path = f"data/ground_truth/{agent_type}/{base_name}.json"

        if not os.path.exists(gt_path):
            return {}

        try:
            with open(gt_path, 'r', encoding='utf-8') as f:
                gt_data = json.load(f)
                self.ground_truth_cache[cache_key] = gt_data
                return gt_data
        except:
            return {}

    def extract_expected_algorithms(self, ground_truth):
        """Ground truthì—ì„œ ì˜ˆìƒ ì•Œê³ ë¦¬ì¦˜ ì¶”ì¶œ"""
        algorithms = []

        # ìƒˆ í˜•ì‹: expected_findings.vulnerable_algorithms_detected
        if 'expected_findings' in ground_truth:
            findings = ground_truth['expected_findings']
            if 'vulnerable_algorithms_detected' in findings:
                algos = findings['vulnerable_algorithms_detected']
                if isinstance(algos, list):
                    algorithms.extend([a.upper() for a in algos if isinstance(a, str)])

            # Korean algorithmsë„ ì¶”ê°€
            if 'korean_algorithms_detected' in findings:
                algos = findings['korean_algorithms_detected']
                if isinstance(algos, list):
                    algorithms.extend([a.upper() for a in algos if isinstance(a, str)])

        # ê¸°ì¡´ í˜•ì‹: algorithms í•„ë“œ
        elif 'algorithms' in ground_truth:
            for algo in ground_truth['algorithms']:
                if isinstance(algo, dict) and 'name' in algo:
                    algorithms.append(algo['name'].upper())

        return algorithms

    def extract_detected_algorithms(self, actual_response):
        """ì‹¤ì œ ì‘ë‹µì—ì„œ íƒì§€ëœ ì•Œê³ ë¦¬ì¦˜ ì¶”ì¶œ"""
        detected = []
        if not actual_response.get('valid_json', False) and not actual_response.get('json_valid', False):
            return detected

        analysis = actual_response.get('analysis_results', {})

        # algorithms_detected í•„ë“œ
        if 'algorithms_detected' in analysis:
            algos = analysis['algorithms_detected']
            if isinstance(algos, list):
                detected.extend([a.upper() for a in algos if isinstance(a, str)])

        # vulnerable_algorithms í•„ë“œ
        if 'vulnerable_algorithms' in analysis:
            algos = analysis['vulnerable_algorithms']
            if isinstance(algos, list):
                for algo in algos:
                    if isinstance(algo, str):
                        detected.append(algo.upper())
                    elif isinstance(algo, dict) and 'name' in algo:
                        detected.append(algo['name'].upper())

        # quantum_vulnerable_algorithms í•„ë“œ
        if 'quantum_vulnerable_algorithms' in analysis:
            algos = analysis['quantum_vulnerable_algorithms']
            if isinstance(algos, list):
                for algo in algos:
                    if isinstance(algo, str):
                        detected.append(algo.upper())
                    elif isinstance(algo, dict) and 'algorithm' in algo:
                        detected.append(algo['algorithm'].upper())

        # detected_algorithms í•„ë“œ (ìƒˆ í˜•ì‹)
        if 'detected_algorithms' in actual_response:
            algos = actual_response['detected_algorithms']
            if isinstance(algos, list):
                detected.extend([a.upper() for a in algos if isinstance(a, str)])

        # analysis_results ê°’ì—ì„œ DETECTED íŒ¨í„´ ì°¾ê¸°
        import re
        for key, value in analysis.items():
            if isinstance(value, str) and 'DETECTED:' in value.upper():
                matches = re.findall(r'DETECTED:\s*([A-Z0-9\-/]+)', value.upper())
                detected.extend(matches)

        return list(set(detected))

    def normalize_algorithm_name(self, name: str) -> str:
        """ì•Œê³ ë¦¬ì¦˜ ì´ë¦„ ì •ê·œí™”"""
        name = name.upper().strip()
        mappings = {
            'TRIPLE DES': '3DES', 'TRIPLE-DES': '3DES', 'TDES': '3DES',
            'EC-KCDSA': 'KCDSA', 'ECKCDSA': 'KCDSA',
            'DIFFIE-HELLMAN': 'DH', 'DIFFIE HELLMAN': 'DH',
            'SHA1': 'SHA-1', 'SHA256': 'SHA-256', 'SHA512': 'SHA-512',
        }
        for pattern, replacement in mappings.items():
            if pattern in name:
                return replacement
        return name

    def check_algorithm_match(self, expected: str, detected_list: list) -> bool:
        """ì•Œê³ ë¦¬ì¦˜ ë§¤ì¹­ í™•ì¸"""
        expected_norm = self.normalize_algorithm_name(expected)
        detected_norm = [self.normalize_algorithm_name(d) for d in detected_list]

        if expected_norm in detected_norm:
            return True

        for detected in detected_norm:
            if expected_norm in detected or detected in expected_norm:
                return True
        return False

    def collect_algorithm_stats(self):
        """ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ í†µê³„ ìˆ˜ì§‘"""
        overall_stats = defaultdict(lambda: {'expected': 0, 'detected': 0, 'missed': 0})
        model_stats = defaultdict(lambda: defaultdict(lambda: {'expected': 0, 'detected': 0, 'missed': 0}))

        for result in self.results_data.get('results', []):
            # í•„ë“œëª… ë§¤í•‘: model ë˜ëŠ” model_name
            model_name = result.get('model', result.get('model_name', 'unknown'))
            # íŒŒì¼ ê²½ë¡œì—ì„œ íŒŒì¼ëª… ì¶”ì¶œ
            file_path = result.get('file_path', result.get('file_name', ''))
            file_name = os.path.basename(file_path) if file_path else ''
            agent_type = result.get('agent_type', '')

            gt = self.load_ground_truth(file_name, agent_type)
            if not gt:
                continue

            expected_algos = self.extract_expected_algorithms(gt)
            if not expected_algos:
                continue

            detected_algos = self.extract_detected_algorithms(result)

            for expected in expected_algos:
                expected_norm = self.normalize_algorithm_name(expected)

                overall_stats[expected_norm]['expected'] += 1
                model_stats[model_name][expected_norm]['expected'] += 1

                if self.check_algorithm_match(expected, detected_algos):
                    overall_stats[expected_norm]['detected'] += 1
                    model_stats[model_name][expected_norm]['detected'] += 1
                else:
                    overall_stats[expected_norm]['missed'] += 1
                    model_stats[model_name][expected_norm]['missed'] += 1

        return overall_stats, model_stats

    def plot_overall_detection_rate(self, overall_stats, output_file='algorithm_detection_overall.png'):
        """ì „ì²´ ì•Œê³ ë¦¬ì¦˜ íƒì§€ìœ¨ ë§‰ëŒ€ ê·¸ë˜í”„"""
        algorithms = sorted(overall_stats.keys(),
                          key=lambda x: overall_stats[x]['detected'] / max(overall_stats[x]['expected'], 1),
                          reverse=True)

        detection_rates = []
        expected_counts = []

        for algo in algorithms:
            stats = overall_stats[algo]
            rate = stats['detected'] / max(stats['expected'], 1) * 100
            detection_rates.append(rate)
            expected_counts.append(stats['expected'])

        fig, ax = plt.subplots(figsize=(14, 8))

        colors = ['#2ecc71' if r >= 80 else '#f39c12' if r >= 50 else '#e74c3c' for r in detection_rates]
        bars = ax.barh(algorithms, detection_rates, color=colors, alpha=0.8)

        # ê°’ í‘œì‹œ
        for i, (bar, rate, count) in enumerate(zip(bars, detection_rates, expected_counts)):
            ax.text(rate + 2, i, f'{rate:.1f}% ({count} tests)',
                   va='center', fontsize=10)

        ax.set_xlabel('Detection Rate (%)', fontsize=12, fontweight='bold')
        ax.set_title('Algorithm Detection Rate (All Models Combined)',
                    fontsize=14, fontweight='bold', pad=20)
        ax.set_xlim(0, 110)
        ax.grid(axis='x', alpha=0.3, linestyle='--')

        # ë²”ë¡€
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#2ecc71', label='Excellent (â‰¥80%)'),
            Patch(facecolor='#f39c12', label='Moderate (50-80%)'),
            Patch(facecolor='#e74c3c', label='Poor (<50%)')
        ]
        ax.legend(handles=legend_elements, loc='lower right', fontsize=10)

        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"âœ… ì €ì¥: {output_file}")
        plt.close()

    def plot_model_comparison_heatmap(self, model_stats, output_file='algorithm_detection_by_model.png'):
        """ëª¨ë¸ë³„ ì•Œê³ ë¦¬ì¦˜ íƒì§€ìœ¨ íˆíŠ¸ë§µ"""
        # ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ ìˆ˜ì§‘
        all_algorithms = set()
        for model_data in model_stats.values():
            all_algorithms.update(model_data.keys())

        algorithms = sorted(all_algorithms)
        models = sorted(model_stats.keys())

        # ë°ì´í„° ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
        data = np.zeros((len(algorithms), len(models)))

        for i, algo in enumerate(algorithms):
            for j, model in enumerate(models):
                stats = model_stats[model].get(algo, {'expected': 0, 'detected': 0})
                if stats['expected'] > 0:
                    data[i, j] = stats['detected'] / stats['expected'] * 100
                else:
                    data[i, j] = np.nan

        fig, ax = plt.subplots(figsize=(12, max(8, len(algorithms) * 0.4)))

        sns.heatmap(data, annot=True, fmt='.1f', cmap='RdYlGn',
                   xticklabels=models, yticklabels=algorithms,
                   vmin=0, vmax=100, cbar_kws={'label': 'Detection Rate (%)'},
                   linewidths=0.5, ax=ax)

        ax.set_title('Algorithm Detection Rate by Model (%)',
                    fontsize=14, fontweight='bold', pad=20)
        ax.set_xlabel('Model', fontsize=12, fontweight='bold')
        ax.set_ylabel('Algorithm', fontsize=12, fontweight='bold')

        plt.xticks(rotation=45, ha='right')
        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"âœ… ì €ì¥: {output_file}")
        plt.close()

    def plot_success_failure_stacked(self, overall_stats, output_file='algorithm_success_failure.png'):
        """ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ê³µ/ì‹¤íŒ¨ ìŠ¤íƒ ë°” ì°¨íŠ¸"""
        algorithms = sorted(overall_stats.keys(),
                          key=lambda x: overall_stats[x]['detected'] / max(overall_stats[x]['expected'], 1),
                          reverse=True)

        detected = [overall_stats[a]['detected'] for a in algorithms]
        missed = [overall_stats[a]['missed'] for a in algorithms]

        fig, ax = plt.subplots(figsize=(14, 8))

        x = np.arange(len(algorithms))
        width = 0.7

        p1 = ax.bar(x, detected, width, label='Detected', color='#2ecc71', alpha=0.8)
        p2 = ax.bar(x, missed, width, bottom=detected, label='Missed', color='#e74c3c', alpha=0.8)

        ax.set_ylabel('Number of Tests', fontsize=12, fontweight='bold')
        ax.set_title('Algorithm Detection Success vs Failure',
                    fontsize=14, fontweight='bold', pad=20)
        ax.set_xticks(x)
        ax.set_xticklabels(algorithms, rotation=45, ha='right')
        ax.legend(fontsize=11)
        ax.grid(axis='y', alpha=0.3, linestyle='--')

        # í¼ì„¼íŠ¸ í‘œì‹œ
        for i, (d, m) in enumerate(zip(detected, missed)):
            total = d + m
            if total > 0:
                percentage = d / total * 100
                ax.text(i, total + 1, f'{percentage:.0f}%',
                       ha='center', va='bottom', fontsize=9, fontweight='bold')

        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"âœ… ì €ì¥: {output_file}")
        plt.close()

    def plot_top_bottom_algorithms(self, overall_stats, output_file='algorithm_top_bottom.png'):
        """ìƒìœ„/í•˜ìœ„ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ"""
        algo_rates = []
        for algo, stats in overall_stats.items():
            if stats['expected'] >= 5:  # ìµœì†Œ 5ê°œ í…ŒìŠ¤íŠ¸ ì´ìƒ
                rate = stats['detected'] / stats['expected'] * 100
                algo_rates.append((algo, rate, stats['expected']))

        algo_rates.sort(key=lambda x: x[1], reverse=True)

        top_5 = algo_rates[:5]
        bottom_5 = algo_rates[-5:]

        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))

        # Top 5
        algos_top = [a[0] for a in top_5]
        rates_top = [a[1] for a in top_5]
        counts_top = [a[2] for a in top_5]

        bars1 = ax1.barh(algos_top, rates_top, color='#2ecc71', alpha=0.8)
        for i, (bar, rate, count) in enumerate(zip(bars1, rates_top, counts_top)):
            ax1.text(rate + 2, i, f'{rate:.1f}% ({count})', va='center')

        ax1.set_xlabel('Detection Rate (%)', fontsize=12, fontweight='bold')
        ax1.set_title('Top 5 Best Detected Algorithms', fontsize=13, fontweight='bold')
        ax1.set_xlim(0, 110)
        ax1.grid(axis='x', alpha=0.3, linestyle='--')

        # Bottom 5
        algos_bottom = [a[0] for a in bottom_5]
        rates_bottom = [a[1] for a in bottom_5]
        counts_bottom = [a[2] for a in bottom_5]

        bars2 = ax2.barh(algos_bottom, rates_bottom, color='#e74c3c', alpha=0.8)
        for i, (bar, rate, count) in enumerate(zip(bars2, rates_bottom, counts_bottom)):
            ax2.text(rate + 2, i, f'{rate:.1f}% ({count})', va='center')

        ax2.set_xlabel('Detection Rate (%)', fontsize=12, fontweight='bold')
        ax2.set_title('Bottom 5 Worst Detected Algorithms', fontsize=13, fontweight='bold')
        ax2.set_xlim(0, 110)
        ax2.grid(axis='x', alpha=0.3, linestyle='--')

        plt.tight_layout()
        plt.savefig(output_file, dpi=300, bbox_inches='tight')
        print(f"âœ… ì €ì¥: {output_file}")
        plt.close()

    def generate_all_plots(self, output_dir='.'):
        """ëª¨ë“  ê·¸ë˜í”„ ìƒì„±"""
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)

        overall_stats, model_stats = self.collect_algorithm_stats()

        if not overall_stats:
            print("âš ï¸  ì•Œê³ ë¦¬ì¦˜ í†µê³„ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("\nğŸ“Š ì•Œê³ ë¦¬ì¦˜ íƒì§€ ê·¸ë˜í”„ ìƒì„± ì¤‘...\n")

        self.plot_overall_detection_rate(
            overall_stats,
            os.path.join(output_dir, 'algorithm_detection_overall.png')
        )

        self.plot_model_comparison_heatmap(
            model_stats,
            os.path.join(output_dir, 'algorithm_detection_by_model.png')
        )

        self.plot_success_failure_stacked(
            overall_stats,
            os.path.join(output_dir, 'algorithm_success_failure.png')
        )

        self.plot_top_bottom_algorithms(
            overall_stats,
            os.path.join(output_dir, 'algorithm_top_bottom.png')
        )

        print("\nâœ… ëª¨ë“  ì•Œê³ ë¦¬ì¦˜ íƒì§€ ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ!")


def main():
    parser = argparse.ArgumentParser(description='ì•Œê³ ë¦¬ì¦˜ íƒì§€ìœ¨ ì‹œê°í™”')
    parser.add_argument('--file', '-f', help='ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ JSON íŒŒì¼')
    parser.add_argument('--output-dir', '-o', default='.', help='ì¶œë ¥ ë””ë ‰í† ë¦¬')

    args = parser.parse_args()

    visualizer = AlgorithmDetectionVisualizer(args.file)

    if not visualizer.load_results():
        return

    visualizer.generate_all_plots(args.output_dir)


if __name__ == "__main__":
    main()
