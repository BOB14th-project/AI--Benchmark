# ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™” ê°€ì´ë“œ

ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ í›„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì‹œê°í™”í•˜ëŠ” ëª¨ë“  ëª…ë ¹ì–´ ëª¨ìŒ

## ğŸ“ ê²°ê³¼ íŒŒì¼ ìœ„ì¹˜

ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ í›„ ìƒì„±ë˜ëŠ” íŒŒì¼ë“¤:
```
benchmark_results_YYYYMMDD_HHMMSS.json  # ìƒì„¸ ê²°ê³¼ (JSON)
benchmark_results_YYYYMMDD_HHMMSS.csv   # ìš”ì•½ ê²°ê³¼ (CSV)
```

---

## ğŸ” 1. ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„

### ì „ì²´ ë¶„ì„ (ëª¨ë¸ë³„ + í†µí•©)
```bash
python3 analyze_algorithm_detection.py
```

### ëª¨ë¸ë³„ ë¶„ì„ë§Œ
```bash
python3 analyze_algorithm_detection.py --by-model
```

### ì „ì²´ í†µí•© ë¶„ì„ë§Œ
```bash
python3 analyze_algorithm_detection.py --overall
```

### íŠ¹ì • ê²°ê³¼ íŒŒì¼ ì§€ì •
```bash
python3 analyze_algorithm_detection.py --file benchmark_results_20250111_143022.json
```

**ì¶œë ¥ ì˜ˆì‹œ:**
```
ğŸ“Š ëª¨ë¸ë³„ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„
=================================

ğŸ¤– ëª¨ë¸: gemini-2.5-flash
   ì´ í…ŒìŠ¤íŠ¸: 50ê°œ
   ì´ ì˜ˆìƒ ì•Œê³ ë¦¬ì¦˜: 75ê°œ
   ì´ íƒì§€ ì„±ê³µ: 65ê°œ (86.7%)
   ì´ íƒì§€ ì‹¤íŒ¨: 10ê°œ (13.3%)

   ğŸ“ˆ ì•Œê³ ë¦¬ì¦˜ë³„ íƒì§€ìœ¨:
      âœ… RSA            :  25/ 25 (100.0%)
      âœ… AES            :  15/ 15 (100.0%)
      âš ï¸  SEED          :   8/ 12 ( 66.7%)
      âŒ ARIA          :   5/ 10 ( 50.0%)
```

---

## ğŸ“ˆ 2. ê·¸ë˜í”„ ìƒì„±

### 2.1 ì•Œê³ ë¦¬ì¦˜ íƒì§€ìœ¨ ì‹œê°í™” (ì‹ ê·œ! ğŸ†•)
```bash
python3 visualize_algorithm_detection.py
```

ìƒì„±ë˜ëŠ” ê·¸ë˜í”„:
- `algorithm_detection_overall.png` - ì „ì²´ ì•Œê³ ë¦¬ì¦˜ íƒì§€ìœ¨ ë§‰ëŒ€ ê·¸ë˜í”„
- `algorithm_detection_by_model.png` - ëª¨ë¸ë³„ ì•Œê³ ë¦¬ì¦˜ íƒì§€ìœ¨ íˆíŠ¸ë§µ
- `algorithm_success_failure.png` - ì•Œê³ ë¦¬ì¦˜ë³„ ì„±ê³µ/ì‹¤íŒ¨ ìŠ¤íƒ ë°” ì°¨íŠ¸
- `algorithm_top_bottom.png` - ìƒìœ„/í•˜ìœ„ ì•Œê³ ë¦¬ì¦˜ ë¹„êµ

### 2.2 ì „ì²´ ì„±ëŠ¥ ê·¸ë˜í”„ ìƒì„±
```bash
# ì—ì´ì „íŠ¸ ì„±ëŠ¥
python3 visualize_agent_performance.py

# ì‘ë‹µ ì‹œê°„ ë¶„ì„
python3 visualize_response_time.py
```

ìƒì„±ë˜ëŠ” ê·¸ë˜í”„:
- `agent_model_heatmap_f1_score.png` - ì—ì´ì „íŠ¸Ã—ëª¨ë¸ F1 ì ìˆ˜ íˆíŠ¸ë§µ
- `agent_response_time_heatmap.png` - ì‘ë‹µ ì‹œê°„ íˆíŠ¸ë§µ
- `agent_response_time_comparison.png` - ì‘ë‹µ ì‹œê°„ ë¹„êµ ë°” ì°¨íŠ¸
- `agent_response_time_boxplot.png` - ì‘ë‹µ ì‹œê°„ ë°•ìŠ¤í”Œë¡¯
- `agent_model_rankings.png` - ëª¨ë¸ë³„ ìˆœìœ„
- `agent_best_models.png` - ì—ì´ì „íŠ¸ë³„ ìµœì  ëª¨ë¸

### 2.3 íŠ¹ì • ê²°ê³¼ íŒŒì¼ë¡œ ê·¸ë˜í”„ ìƒì„±
```bash
# ì•Œê³ ë¦¬ì¦˜ íƒì§€ìœ¨
python3 visualize_algorithm_detection.py --file benchmark_results_20250111_143022.json

# ì—ì´ì „íŠ¸ ì„±ëŠ¥
python3 visualize_agent_performance.py --file benchmark_results_20250111_143022.json
```

### 2.4 ì¶œë ¥ ë””ë ‰í† ë¦¬ ì§€ì •
```bash
python3 visualize_algorithm_detection.py --output-dir ./visualizations
```

---

## ğŸ“Š 3. ìƒì„¸ í†µê³„ ë¶„ì„

### 3.1 ê¸°ë³¸ í†µê³„ ì¶œë ¥
```bash
python3 -c "
import json
with open('benchmark_results_*.json', 'r') as f:
    data = json.load(f)
    print(f\"ì´ í…ŒìŠ¤íŠ¸: {data['summary']['total_tests']}\")
    print(f\"ì„±ê³µ: {data['summary']['successful_tests']}\")
    print(f\"ì„±ê³µë¥ : {data['summary']['success_rate']:.1%}\")
"
```

### 3.2 ëª¨ë¸ë³„ í‰ê·  ì„±ëŠ¥
```bash
python3 -c "
import json
from collections import defaultdict

with open('benchmark_results_*.json', 'r') as f:
    data = json.load(f)

model_stats = defaultdict(lambda: {'f1': [], 'time': []})

for result in data['results']:
    model = result['model_name']
    model_stats[model]['f1'].append(result.get('f1_score', 0))
    model_stats[model]['time'].append(result.get('response_time', 0))

for model, stats in model_stats.items():
    avg_f1 = sum(stats['f1']) / len(stats['f1'])
    avg_time = sum(stats['time']) / len(stats['time'])
    print(f\"{model}: F1={avg_f1:.3f}, Time={avg_time:.2f}s\")
"
```

### 3.3 ì—ì´ì „íŠ¸ë³„ í‰ê·  ì„±ëŠ¥
```bash
python3 -c "
import json
from collections import defaultdict

with open('benchmark_results_*.json', 'r') as f:
    data = json.load(f)

agent_stats = defaultdict(lambda: {'f1': [], 'accuracy': []})

for result in data['results']:
    agent = result['agent_type']
    agent_stats[agent]['f1'].append(result.get('f1_score', 0))
    agent_stats[agent]['accuracy'].append(result.get('accuracy', 0))

for agent, stats in agent_stats.items():
    avg_f1 = sum(stats['f1']) / len(stats['f1'])
    avg_acc = sum(stats['accuracy']) / len(stats['accuracy'])
    print(f\"{agent}: F1={avg_f1:.3f}, Accuracy={avg_acc:.3f}\")
"
```

---

## ğŸ¯ 4. ì¢…í•© ë¶„ì„ ì›Œí¬í”Œë¡œìš°

### ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ë¶€í„° ì‹œê°í™”ê¹Œì§€ ì „ì²´ ê³¼ì •:

```bash
# 1. ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
python3 benchmark_runner.py

# 2. í…ìŠ¤íŠ¸ ë¶„ì„ (ì½˜ì†” ì¶œë ¥)
python3 analyze_algorithm_detection.py > algorithm_analysis.txt

# 3. ê·¸ë˜í”„ ìƒì„±
python3 visualize_algorithm_detection.py    # ì•Œê³ ë¦¬ì¦˜ íƒì§€ìœ¨ ê·¸ë˜í”„
python3 visualize_agent_performance.py      # ì—ì´ì „íŠ¸ ì„±ëŠ¥ ê·¸ë˜í”„
python3 visualize_response_time.py          # ì‘ë‹µ ì‹œê°„ ê·¸ë˜í”„

# 4. ê²°ê³¼ í™•ì¸
cat algorithm_analysis.txt
ls *.png
```

### í•œ ì¤„ ëª…ë ¹ì–´ë¡œ ëª¨ë“  ë¶„ì„ ì‹¤í–‰:
```bash
python3 benchmark_runner.py && \
python3 analyze_algorithm_detection.py > algorithm_analysis.txt && \
python3 visualize_algorithm_detection.py && \
python3 visualize_agent_performance.py && \
python3 visualize_response_time.py && \
echo "âœ… ë¶„ì„ ì™„ë£Œ! ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”."
```

---

## ğŸ“‚ 5. Google Drive ë°±ì—… (Colab ìš©)

### ìë™ ë°±ì—… (ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘)
```python
import os
os.environ['GDRIVE_RESULTS_DIR'] = '/content/drive/MyDrive/AI_Benchmark_Results'
```

### ìˆ˜ë™ ë°±ì—…
```bash
python3 utils/backup_to_gdrive.py
```

---

## ğŸ’¾ 6. CSVë¡œ ê²°ê³¼ ë‚´ë³´ë‚´ê¸°

### JSON â†’ CSV ë³€í™˜
```bash
python3 -c "
import json
import csv

with open('benchmark_results_*.json', 'r') as f:
    data = json.load(f)

with open('detailed_results.csv', 'w', newline='') as f:
    writer = csv.writer(f)
    writer.writerow(['Model', 'Agent', 'File', 'F1 Score', 'Accuracy', 'Precision', 'Recall', 'Response Time'])

    for result in data['results']:
        writer.writerow([
            result['model_name'],
            result['agent_type'],
            result['file_name'],
            result.get('f1_score', 0),
            result.get('accuracy', 0),
            result.get('precision', 0),
            result.get('recall', 0),
            result.get('response_time', 0)
        ])
"
```

---

## ğŸ”„ 7. ê²°ê³¼ ë¹„êµ (ì—¬ëŸ¬ ë²¤ì¹˜ë§ˆí¬)

### ë‘ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¹„êµ
```bash
python3 compare_benchmarks.py \
    --file1 benchmark_results_20250110_120000.json \
    --file2 benchmark_results_20250111_143022.json
```

### ì‹œê³„ì—´ ì„±ëŠ¥ ì¶”ì´
```bash
python3 plot_performance_trend.py --pattern "benchmark_results_*.json"
```

---

## ğŸ“‹ 8. ë¹ ë¥¸ ëª…ë ¹ì–´ ì²´í¬ë¦¬ìŠ¤íŠ¸

```bash
# âœ… ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„ (í…ìŠ¤íŠ¸)
python3 analyze_algorithm_detection.py

# âœ… ì•Œê³ ë¦¬ì¦˜ íƒì§€ ê·¸ë˜í”„ ìƒì„± â­
python3 visualize_algorithm_detection.py

# âœ… ì „ì²´ ì„±ëŠ¥ ê·¸ë˜í”„ ìƒì„±
python3 visualize_agent_performance.py
python3 visualize_response_time.py

# âœ… ê²°ê³¼ ë°±ì—… (Colab)
python3 utils/backup_to_gdrive.py

# âœ… ìµœì‹  ê²°ê³¼ í™•ì¸
ls -lht benchmark_results_*.json | head -1

# âœ… ìš”ì•½ í†µê³„
python3 -c "import json; data=json.load(open('benchmark_results_*.json')); print(data['summary'])"
```

---

## ğŸ¨ 9. ì‹œê°í™” ì»¤ìŠ¤í„°ë§ˆì´ì§•

### ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ë³€ê²½
```bash
# ë‹¤í¬ í…Œë§ˆ
python3 visualize_results.py --style dark

# ì»¬ëŸ¬ íŒ”ë ˆíŠ¸ ë³€ê²½
python3 visualize_results.py --palette viridis

# í•´ìƒë„ ì¡°ì • (DPI)
python3 visualize_results.py --dpi 300
```

### í°íŠ¸ í¬ê¸° ì¡°ì •
```bash
python3 visualize_results.py --fontsize 14
```

---

## ğŸš€ 10. Colabì—ì„œ í•œë²ˆì— ì‹¤í–‰

```python
# Colab ë…¸íŠ¸ë¶ì—ì„œ ì‹¤í–‰
!cd /content/AI--Benchmark

# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
!python3 benchmark_runner.py

# ë¶„ì„ ë° ì‹œê°í™”
!python3 analyze_algorithm_detection.py > algorithm_analysis.txt
!python3 visualize_results.py

# ê²°ê³¼ í™•ì¸
!cat algorithm_analysis.txt
from IPython.display import Image, display
for img in ['agent_model_heatmap_f1_score.png', 'agent_response_time_comparison.png']:
    display(Image(img))

# Google Drive ë°±ì—…
!python3 utils/backup_to_gdrive.py
```

---

## ğŸ“Œ ìœ ìš©í•œ íŒ

### 1. ìµœì‹  ê²°ê³¼ íŒŒì¼ ìë™ ì„ íƒ
```bash
LATEST=$(ls -t benchmark_results_*.json | head -1)
python3 analyze_algorithm_detection.py --file $LATEST
python3 visualize_results.py --file $LATEST
```

### 2. ê²°ê³¼ ì••ì¶• ë° ë‹¤ìš´ë¡œë“œ
```bash
# ëª¨ë“  ê²°ê³¼ ì••ì¶•
tar -czf benchmark_results.tar.gz benchmark_results_* *.png algorithm_analysis.txt

# Colabì—ì„œ ë‹¤ìš´ë¡œë“œ
from google.colab import files
files.download('benchmark_results.tar.gz')
```

### 3. ì‹¤ì‹œê°„ ë¡œê·¸ ëª¨ë‹ˆí„°ë§
```bash
# ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ë¡œê·¸ í™•ì¸
tail -f benchmark.log
```

---

## ğŸ¯ ê¶Œì¥ ë¶„ì„ ìˆœì„œ

1. **ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë¶„ì„** ë¨¼ì € ì‹¤í–‰
   ```bash
   python3 analyze_algorithm_detection.py
   ```

2. **ê·¸ë˜í”„ ìƒì„±**ìœ¼ë¡œ ì‹œê°í™”
   ```bash
   python3 visualize_results.py
   ```

3. **ê²°ê³¼ ë°±ì—…** (ì„ íƒ)
   ```bash
   python3 utils/backup_to_gdrive.py
   ```

4. **ìƒì„¸ ë¶„ì„** (í•„ìš”ì‹œ)
   - CSV ë³€í™˜
   - ì»¤ìŠ¤í…€ í†µê³„ ì¶”ì¶œ

---

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ë©´ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ë¥¼ ì™„ë²½í•˜ê²Œ ë¶„ì„í•˜ê³  ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤! ğŸ‰
