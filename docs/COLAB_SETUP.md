# Google Colabì—ì„œ AI Benchmark ì‹¤í–‰í•˜ê¸°

ì´ ê°€ì´ë“œëŠ” Google Colab í™˜ê²½ì—ì„œ ì–‘ì ì·¨ì•½ ì•”í˜¸ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì„ ì„¤ëª…í•©ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ìƒˆ Colab ë…¸íŠ¸ë¶ ìƒì„±

1. [Google Colab](https://colab.research.google.com/)ì— ì ‘ì†
2. `íŒŒì¼` â†’ `ìƒˆ ë…¸íŠ¸ë¶` í´ë¦­

### 2. ì €ì¥ì†Œ í´ë¡  ë° ì„¤ì¹˜

ë‹¤ìŒ ì…€ì„ ìˆœì„œëŒ€ë¡œ ì‹¤í–‰í•˜ì„¸ìš”:

```python
# 1. ì €ì¥ì†Œ í´ë¡ 
!git clone https://github.com/your-username/AI--Benchmark.git
%cd AI--Benchmark

# 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
!pip install -q openai google-generativeai anthropic requests pyyaml python-dotenv numpy pandas psutil

# 3. ì„¤ì¹˜ í™•ì¸
!python -c "import openai; import google.generativeai as genai; print('ì„¤ì¹˜ ì™„ë£Œ!')"
```

### 3. API í‚¤ ì„¤ì •

Colab Secretsë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ API í‚¤ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤:

#### 3-1. Colab Secretsì— API í‚¤ ì¶”ê°€

1. ì¢Œì¸¡ ì‚¬ì´ë“œë°”ì—ì„œ **ğŸ”‘ Secrets** ì•„ì´ì½˜ í´ë¦­
2. ë‹¤ìŒ í‚¤ë“¤ì„ ì¶”ê°€:
   - `GOOGLE_API_KEY`: Google Gemini API í‚¤
   - `OPENAI_API_KEY`: OpenAI GPT API í‚¤
   - `XAI_API_KEY`: xAI Grok API í‚¤ (ì„ íƒ)
\
#### 3-2. í™˜ê²½ ë³€ìˆ˜ë¡œ ì„¤ì •

```python
from google.colab import userdata
import os

# API í‚¤ ì„¤ì •
os.environ['GOOGLE_API_KEY'] = userdata.get('GOOGLE_API_KEY')
os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')
os.environ['XAI_API_KEY'] = userdata.get('XAI_API_KEY')




# ëª¨ë¸ ë° ì—”ë“œí¬ì¸íŠ¸ ì„¤ì •
os.environ['GOOGLE_MODEL'] = 'gemini-2.5-flash'
os.environ['GOOGLE_BASE_URL'] = 'https://generativelanguage.googleapis.com/v1beta'

os.environ['OPENAI_MODEL'] = 'gpt-4.1'
os.environ['OPENAI_BASE_URL'] = 'https://api.openai.com/v1'

os.environ['XAI_MODEL'] = 'grok-3-mini'
os.environ['XAI_BASE_URL'] = 'https://api.x.ai/v1'

print("âœ… API í‚¤ ì„¤ì • ì™„ë£Œ!")
```

### 4. Ollama ë¡œì»¬ ëª¨ë¸ ì„¤ì¹˜

Colab Pro/Pro+ì—ì„œ Ollamaë¥¼ ì‚¬ìš©í•˜ì—¬ ë¡œì»¬ì—ì„œ LLM ëª¨ë¸ì„ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

#### 4-1. Ollama ì„¤ì¹˜

```python
# Ollama ì„¤ì¹˜ (ì•½ 2-3ë¶„ ì†Œìš”)
!curl -fsSL https://ollama.com/install.sh | sh

# ì„¤ì¹˜ í™•ì¸
!ollama --version
```

#### 4-2. Ollama ì„œë²„ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰

```python
# ë°±ê·¸ë¼ìš´ë“œì—ì„œ Ollama ì„œë²„ ì‹œì‘
import subprocess
import time

# Ollama ì„œë²„ ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ)
ollama_process = subprocess.Popen(
    ['ollama', 'serve'],
    stdout=subprocess.PIPE,
    stderr=subprocess.PIPE
)

# ì„œë²„ ì‹œì‘ ëŒ€ê¸°
print("â³ Ollama ì„œë²„ ì‹œì‘ ì¤‘...")
time.sleep(5)
print("âœ… Ollama ì„œë²„ ì‹œì‘ ì™„ë£Œ!")
```

#### 4-3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```python
# ì›í•˜ëŠ” ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ê° ëª¨ë¸ì€ ì•½ 4-8GB)
# ê²½ê³ : Colab ë¬´ë£Œ ë²„ì „ì€ ë””ìŠ¤í¬ ê³µê°„ ì œí•œì´ ìˆìœ¼ë¯€ë¡œ 1-2ê°œ ëª¨ë¸ë§Œ ê¶Œì¥

# ì˜µì…˜ 1: LLaMA 3 (ì•½ 4.7GB)
!ollama pull llama3:8b

# ì˜µì…˜ 2: Qwen 3 (ì•½ 5.2GB)
!ollama pull qwen3:8b

# ì˜µì…˜ 3: Code Llama (ì•½ 3.8GB)
!ollama pull codellama:7b

# ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ í™•ì¸
!ollama list
```

#### 4-4. Ollama í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```python
# ë¨¼ì € ë‹¤ìš´ë¡œë“œí•œ ëª¨ë“  ëª¨ë¸ í™•ì¸
!ollama list

# ë°©ë²• 1: ë‹¨ì¼ ëª¨ë¸ ì„¤ì •
os.environ['OLLAMA_MODEL'] = 'llama3:8b'
os.environ['OLLAMA_BASE_URL'] = 'http://localhost:11434'
print("âœ… Ollama ë‹¨ì¼ ëª¨ë¸ ì„¤ì • ì™„ë£Œ!")

# ë°©ë²• 2: ì—¬ëŸ¬ ëª¨ë¸ ì‚¬ìš© - ì‰¼í‘œë¡œ êµ¬ë¶„ (ê¶Œì¥, ê°€ì¥ ê°„ë‹¨)
os.environ['OLLAMA_MODEL'] = 'llama3:8b,qwen3:8b,codellama:7b'
os.environ['OLLAMA_BASE_URL'] = 'http://localhost:11434'
print("âœ… Ollama ë‹¤ì¤‘ ëª¨ë¸ ì„¤ì • ì™„ë£Œ!")

# ë°©ë²• 3: JSON ë°°ì—´ í˜•ì‹ (ê³ ê¸‰)
import json
ollama_models = ['llama3:8b', 'qwen3:8b', 'codellama:7b']
os.environ['OLLAMA_MODEL'] = json.dumps(ollama_models)
os.environ['OLLAMA_BASE_URL'] = 'http://localhost:11434'
print(f"âœ… Ollama ì„¤ì • ì™„ë£Œ! ëª¨ë¸: {ollama_models}")
```

**ğŸ’¡ íŒ:**
- **ê°€ì¥ ê¶Œì¥**: ì‰¼í‘œ êµ¬ë¶„ í˜•ì‹ `'llama3:8b,qwen3:8b,codellama:7b'`
- ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì‹œ ì„¤ì •í•œ ëª¨ë“  ëª¨ë¸ì´ ìˆœì°¨ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸ë©ë‹ˆë‹¤
- JSON ë°°ì—´ í˜•ì‹ì€ ê³ ê¸‰ ì‚¬ìš©ììš© (ì£¼ì˜: ì´ì¤‘ ì¸ì½”ë”© ë¬¸ì œ ê°€ëŠ¥)

#### 4-5. Ollama ì—°ê²° í…ŒìŠ¤íŠ¸

```python
# Ollama ì„œë²„ ì—°ê²° í…ŒìŠ¤íŠ¸
import requests

try:
    response = requests.get('http://localhost:11434/api/tags', timeout=5)
    if response.status_code == 200:
        models = response.json().get('models', [])
        print(f"âœ… Ollama ì—°ê²° ì„±ê³µ! ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {[m['name'] for m in models]}")
    else:
        print(f"âŒ Ollama ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
except Exception as e:
    print(f"âŒ Ollama ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
```

**âš ï¸ ì¤‘ìš” ì‚¬í•­:**
- **Colab Pro/Pro+ ê¶Œì¥**: ë” ë§ì€ ë””ìŠ¤í¬ ê³µê°„ê³¼ ë©”ëª¨ë¦¬ ì œê³µ
- ëŸ°íƒ€ì„ ì¢…ë£Œ ì‹œ Ollama ì„œë²„ì™€ ëª¨ë¸ì´ ì‚­ì œë˜ë¯€ë¡œ ì¬ì‹œì‘ í•„ìš”
- ëª¨ë¸ í¬ê¸°ì— ë”°ë¼ ë‹¤ìš´ë¡œë“œ ì‹œê°„ì´ 5-10ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤

#### 4-6. ì¶”ì²œ ëª¨ë¸ ì¡°í•©

```python
# ì˜µì…˜ 1: ë¹ ë¥´ê³  ê°€ë²¼ìš´ ëª¨ë¸ (ê¶Œì¥)
!ollama pull llama3:8b
!ollama pull qwen3:8b

# ì˜µì…˜ 2: ì½”ë“œ íŠ¹í™” ëª¨ë¸
!ollama pull codellama:7b

# ì˜µì…˜ 3: ì„±ëŠ¥ ì¤‘ì‹œ (Colab Pro+ ê¶Œì¥)
!ollama pull llama3:70b
!ollama pull qwen3:14b
```

### 5. Google Drive ë§ˆìš´íŠ¸ (ê²°ê³¼ ìë™ ì €ì¥ìš©, ê¶Œì¥)

```python
from google.colab import drive

# Google Drive ë§ˆìš´íŠ¸
drive.mount('/content/drive')

# ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
import os
results_dir = '/content/drive/MyDrive/AI_Benchmark_Results'
os.makedirs(results_dir, exist_ok=True)

print(f"âœ… Google Drive ë§ˆìš´íŠ¸ ì™„ë£Œ!")
print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ìœ„ì¹˜: {results_dir}")

# ê²°ê³¼ ìë™ ì €ì¥ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['GDRIVE_RESULTS_DIR'] = results_dir
```

### 6. í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸

```python
# í…ŒìŠ¤íŠ¸ íŒŒì¼ í™•ì¸
!ls -la data/test_files/source_code/ | head -10
!ls -la data/test_files/assembly_binary/ | head -10
!ls -la data/test_files/logs_config/ | head -10

print("\nâœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
```

## ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰

**ğŸ’¡ Google Drive ìë™ ë°±ì—… í™œì„±í™”**

ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì „ì— Section 5ì—ì„œ Google Driveë¥¼ ë§ˆìš´íŠ¸í•˜ë©´:
- í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œ ê²°ê³¼ê°€ ìë™ìœ¼ë¡œ Driveì— ë°±ì—…ë©ë‹ˆë‹¤
- 10ê°œ í…ŒìŠ¤íŠ¸ë§ˆë‹¤ ì¤‘ê°„ ì§„í–‰ìƒí™©ì´ ì €ì¥ë©ë‹ˆë‹¤
- ëŸ°íƒ€ì„ ì¢…ë£Œ ì‹œì—ë„ ê²°ê³¼ê°€ ì•ˆì „í•˜ê²Œ ë³´ê´€ë©ë‹ˆë‹¤

### ì˜µì…˜ 1: ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ê¶Œì¥ - ì²˜ìŒ ì‹¤í–‰ ì‹œ)

```python
# Ollama ëª¨ë¸ë§Œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸
!python benchmark_runner.py --providers ollama --agents source_code --limit 3

# Google Driveì— ìë™ ë°±ì—…ë¨ (GDRIVE_RESULTS_DIR ì„¤ì • ì‹œ)
```

### ì˜µì…˜ 2: API ëª¨ë¸ê³¼ ë¹„êµ í…ŒìŠ¤íŠ¸

```python
# Google Gemini + Ollama ë¹„êµ
!python benchmark_runner.py --providers google ollama --agents source_code --limit 5

# OpenAI + Ollama ë¹„êµ
!python benchmark_runner.py --providers openai ollama --agents source_code assembly_binary --limit 5
```

### ì˜µì…˜ 3: ì—¬ëŸ¬ Ollama ëª¨ë¸ í…ŒìŠ¤íŠ¸

```python
# config.yamlì— ì—¬ëŸ¬ ëª¨ë¸ ì„¤ì • í›„ ì‹¤í–‰
# ë˜ëŠ” ê° ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸

# LLaMA 3 í…ŒìŠ¤íŠ¸
os.environ['OLLAMA_MODEL'] = 'llama3:8b'
!python benchmark_runner.py --providers ollama --agents source_code --limit 5 --output llama3_results

# Qwen 3 í…ŒìŠ¤íŠ¸
os.environ['OLLAMA_MODEL'] = 'qwen3:8b'
!python benchmark_runner.py --providers ollama --agents source_code --limit 5 --output qwen3_results

# Code Llama í…ŒìŠ¤íŠ¸
os.environ['OLLAMA_MODEL'] = 'codellama:7b'
!python benchmark_runner.py --providers ollama --agents source_code --limit 5 --output codellama_results
```

### ì˜µì…˜ 4: ì „ì²´ ë²¤ì¹˜ë§ˆí¬ (ì‹œê°„ ì†Œìš”)

```python
# ëª¨ë“  ì—ì´ì „íŠ¸ì™€ í”„ë¡œë°”ì´ë” í…ŒìŠ¤íŠ¸
!python benchmark_runner.py --providers google openai ollama --agents source_code assembly_binary logs_config --limit 10
```

### ì˜µì…˜ 5: ë³‘ë ¬ ì‹¤í–‰ (ë” ë¹ ë¦„)

```python
# ë³‘ë ¬ë¡œ ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ ë™ì‹œ ì‹¤í–‰ (ì£¼ì˜: ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¦ê°€)
!python benchmark_runner.py --providers ollama --agents source_code assembly_binary --limit 5 --parallel
```

## ğŸ“ˆ ê²°ê³¼ í™•ì¸

### ì‹¤ì‹œê°„ ì§„í–‰ ìƒí™©

ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ë‹¤ìŒê³¼ ê°™ì€ ì¶œë ¥ì´ í‘œì‹œë©ë‹ˆë‹¤:

```
ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘
============================================================
âœ… google ëª¨ë¸: ['gemini-2.5-flash']
âœ… openai ëª¨ë¸: ['gpt-4.1']
ğŸ“ source_code: 5ê°œ í…ŒìŠ¤íŠ¸ íŒŒì¼ ë¡œë“œë¨

ğŸ“‹ í…ŒìŠ¤íŠ¸ 1/5: google/gemini-2.5-flash/source_code
    íŒŒì¼: rsa_public_key_system
    âœ… ì™„ë£Œ (12.3ì´ˆ)
    ğŸ¯ ì‹ ë¢°ë„: 0.920
    ğŸ” íƒì§€ëœ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜: RSA, SHA-256
```

### ê²°ê³¼ íŒŒì¼ í™•ì¸

```python
# JSON ê²°ê³¼ í™•ì¸
import json

with open('benchmark_results_[timestamp].json', 'r') as f:
    results = json.load(f)

print(f"ì´ í…ŒìŠ¤íŠ¸: {results['summary']['total_tests']}")
print(f"ì„±ê³µ: {results['summary']['successful_tests']}")
print(f"ì„±ê³µë¥ : {results['summary']['success_rate']:.1%}")
```

### ê²°ê³¼ ë‹¤ìš´ë¡œë“œ

```python
from google.colab import files

# JSON ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
files.download('benchmark_results_[timestamp].json')

# CSV ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
files.download('benchmark_results_[timestamp].csv')
```

### ìˆ˜ë™ìœ¼ë¡œ ê²°ê³¼ ë°±ì—…í•˜ê¸° (ì‹¤í–‰ ì¤‘ì—ë„ ê°€ëŠ¥)

ë²¤ì¹˜ë§ˆí¬ê°€ ì‹¤í–‰ ì¤‘ì¼ ë•Œ ì–¸ì œë“ ì§€ ìˆ˜ë™ìœ¼ë¡œ ë°±ì—…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤:

```python
# ë°©ë²• 1: ìœ í‹¸ë¦¬í‹° ìŠ¤í¬ë¦½íŠ¸ ì‚¬ìš© (ê¶Œì¥)
!python utils/backup_to_gdrive.py

# ë°©ë²• 2: ì§ì ‘ ë³µì‚¬
import shutil
import glob

results_dir = os.environ.get('GDRIVE_RESULTS_DIR')
if results_dir:
    # JSON íŒŒì¼ ë°±ì—…
    for f in glob.glob("benchmark_results_*.json"):
        shutil.copy2(f, results_dir)
        print(f"âœ… ë°±ì—…: {f}")

    # CSV íŒŒì¼ ë°±ì—…
    for f in glob.glob("benchmark_results_*.csv"):
        shutil.copy2(f, results_dir)
        print(f"âœ… ë°±ì—…: {f}")
```

### Google Driveì—ì„œ ê²°ê³¼ í™•ì¸

```python
# Google Driveì— ì €ì¥ëœ ê²°ê³¼ í™•ì¸
results_dir = os.environ.get('GDRIVE_RESULTS_DIR', '/content/drive/MyDrive/AI_Benchmark_Results')
!ls -lh {results_dir}

# ë°±ì—… ëª©ë¡ ìì„¸íˆ ë³´ê¸°
!python utils/backup_to_gdrive.py list

# ê°€ì¥ ìµœê·¼ ê²°ê³¼ íŒŒì¼ ì°¾ê¸°
import glob
json_files = glob.glob(f"{results_dir}/benchmark_results_*.json")
if json_files:
    latest_result = max(json_files, key=os.path.getctime)
    print(f"\nğŸ“Š ìµœì‹  ê²°ê³¼ íŒŒì¼: {latest_result}")

    # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
    import json
    with open(latest_result, 'r') as f:
        result_data = json.load(f)
        print(f"\nì´ í…ŒìŠ¤íŠ¸: {result_data['summary']['total_tests']}")
        print(f"ì„±ê³µ: {result_data['summary']['successful_tests']}")
        print(f"ì„±ê³µë¥ : {result_data['summary']['success_rate']:.1%}")
else:
    print("âŒ ê²°ê³¼ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# ì¤‘ê°„ ë°±ì—… íŒŒì¼ í™•ì¸ (ì§„í–‰ ì¤‘ì¸ í…ŒìŠ¤íŠ¸)
backup_files = glob.glob(f"{results_dir}/backup_progress_*.json")
if backup_files:
    print(f"\nğŸ’¾ ì¤‘ê°„ ë°±ì—… íŒŒì¼: {len(backup_files)}ê°œ")
    latest_backup = max(backup_files, key=os.path.getctime)
    print(f"   ìµœì‹  ë°±ì—…: {os.path.basename(latest_backup)}")
```

## ğŸ“Š ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”

### ê¸°ë³¸ ë¶„ì„

```python
# ê²°ê³¼ ë¶„ì„ ì‹¤í–‰
!python analyze_results.py --compare-models
```

### ì‹œê°í™” ìƒì„±

```python
# ì—ì´ì „íŠ¸ë³„ ì„±ëŠ¥ ë¹„êµ ê·¸ë˜í”„
!python visualize_agent_performance.py

# ì‘ë‹µ ì‹œê°„ ë¹„êµ
!python visualize_response_time.py

# ìƒì„±ëœ ì´ë¯¸ì§€ í™•ì¸
from IPython.display import Image, display
display(Image('results/agent_performance_comparison.png'))
display(Image('results/response_time_comparison.png'))
```

### ìƒì„¸ ë¶„ì„ (Pandas)

```python
import pandas as pd
import matplotlib.pyplot as plt

# CSV ê²°ê³¼ ë¡œë“œ
df = pd.read_csv('benchmark_results_[timestamp].csv')

# ëª¨ë¸ë³„ ì„±ê³µë¥ 
model_success = df.groupby(['provider', 'model'])['success'].mean()
print("\nëª¨ë¸ë³„ ì„±ê³µë¥ :")
print(model_success)

# ì—ì´ì „íŠ¸ë³„ ì„±ê³µë¥ 
agent_success = df.groupby('agent_type')['success'].mean()
print("\nì—ì´ì „íŠ¸ë³„ ì„±ê³µë¥ :")
print(agent_success)

# ì‘ë‹µ ì‹œê°„ ë¶„í¬
plt.figure(figsize=(10, 6))
df.boxplot(column='response_time', by='provider')
plt.title('í”„ë¡œë°”ì´ë”ë³„ ì‘ë‹µ ì‹œê°„ ë¶„í¬')
plt.suptitle('')
plt.ylabel('ì‘ë‹µ ì‹œê°„ (ì´ˆ)')
plt.show()

# íƒì§€ëœ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ ìˆ˜ ë¶„í¬
plt.figure(figsize=(10, 6))
df.boxplot(column='detected_quantum_vulnerable_count', by='agent_type')
plt.title('ì—ì´ì „íŠ¸ë³„ íƒì§€ëœ ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ ìˆ˜')
plt.suptitle('')
plt.ylabel('íƒì§€ ê°œìˆ˜')
plt.show()
```

## ğŸ”§ ë¬¸ì œ í•´ê²°

### API í‚¤ ì˜¤ë¥˜

```python
# API í‚¤ í™•ì¸
import os
print("GOOGLE_API_KEY:", "ì„¤ì •ë¨" if os.getenv('GOOGLE_API_KEY') else "ì—†ìŒ")
print("OPENAI_API_KEY:", "ì„¤ì •ë¨" if os.getenv('OPENAI_API_KEY') else "ì—†ìŒ")
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```python
# í…ŒìŠ¤íŠ¸ ìˆ˜ ì œí•œ
!python benchmark_runner.py --providers google --agents source_code --limit 3
```

### Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨

```python
# Ollama ì„œë²„ ìƒíƒœ í™•ì¸
!ps aux | grep ollama

# Ollama ì„œë²„ ì¬ì‹œì‘
import subprocess
import time

# ê¸°ì¡´ í”„ë¡œì„¸ìŠ¤ ì¢…ë£Œ
!pkill -f "ollama serve"
time.sleep(2)

# ìƒˆë¡œ ì‹œì‘
ollama_process = subprocess.Popen(['ollama', 'serve'], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
time.sleep(5)
print("âœ… Ollama ì„œë²„ ì¬ì‹œì‘ ì™„ë£Œ")

# ì—°ê²° í…ŒìŠ¤íŠ¸
import requests
response = requests.get('http://localhost:11434/api/tags')
print(f"ì—°ê²° ìƒíƒœ: {response.status_code}")
```

### íƒ€ì„ì•„ì›ƒ ì˜¤ë¥˜

```python
# config/config.yaml íŒŒì¼ì—ì„œ íƒ€ì„ì•„ì›ƒ ì„¤ì • í™•ì¸
!cat config/config.yaml | grep timeout
```

### Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨

```python
# ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
!df -h

# ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ
!apt-get clean
!rm -rf /root/.cache/*

# ëª¨ë¸ ì¬ë‹¤ìš´ë¡œë“œ
!ollama pull llama3:8b
```

## ğŸ’¡ ê³ ê¸‰ ì‚¬ìš©ë²•

### íŠ¹ì • íŒŒì¼ë§Œ í…ŒìŠ¤íŠ¸

```python
# ë‹¨ì¼ íŒŒì¼ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
test_code = """
from clients.client_factory import ClientFactory
from agents.agent_factory import AgentFactory
from config.config_loader import ConfigLoader
import os

# ì„¤ì • ë¡œë“œ
config = ConfigLoader()
llm_config = config.get_llm_config('google')

# í´ë¼ì´ì–¸íŠ¸ ë° ì—ì´ì „íŠ¸ ìƒì„±
client = ClientFactory.create_client('google', llm_config)
agent = AgentFactory.create_agent('source_code')

# í…ŒìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°
with open('data/test_files/source_code/rsa_public_key_system.java', 'r') as f:
    test_data = f.read()

# í”„ë¡¬í”„íŠ¸ ìƒì„± ë° ì‹¤í–‰
prompt = agent.create_prompt(test_data)
response = client.benchmark_request(prompt, max_tokens=2000)

# ê²°ê³¼ ì¶œë ¥
if response['success']:
    findings = agent.extract_key_findings(response['content'])
    print("íƒì§€ ê²°ê³¼:", findings['analysis_results'])
else:
    print("ì˜¤ë¥˜:", response['error'])
"""

with open('test_single.py', 'w') as f:
    f.write(test_code)

!python test_single.py
```

### ì»¤ìŠ¤í…€ ë¶„ì„

```python
import pandas as pd
import json

# ê²°ê³¼ ë¡œë“œ
with open('benchmark_results_[timestamp].json', 'r') as f:
    results = json.load(f)

# ìƒì„¸ ê²°ê³¼ ì¶”ì¶œ
detailed = results['detailed_results']

# ì–‘ì ì·¨ì•½ ì•Œê³ ë¦¬ì¦˜ë³„ íƒì§€ìœ¨ ê³„ì‚°
algorithm_detection = {}
for result in detailed:
    if result.get('success') and result.get('valid_json'):
        analysis = result.get('analysis_results', {})
        for category, value in analysis.items():
            if value and value != 'None':
                algorithm_detection[category] = algorithm_detection.get(category, 0) + 1

print("\nì¹´í…Œê³ ë¦¬ë³„ íƒì§€ ë¹ˆë„:")
for algo, count in sorted(algorithm_detection.items(), key=lambda x: x[1], reverse=True):
    print(f"{algo}: {count}íšŒ")
```

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

### ê¸°ë³¸ ì„¤ì •

- [ ] Google Colab ë…¸íŠ¸ë¶ ìƒì„± (Pro/Pro+ ê¶Œì¥)
- [ ] ì €ì¥ì†Œ í´ë¡  ì™„ë£Œ
- [ ] í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ
- [ ] API í‚¤ Colab Secretsì— ì¶”ê°€ (ì„ íƒ ì‚¬í•­)
- [ ] í™˜ê²½ ë³€ìˆ˜ ì„¤ì • ì™„ë£Œ

### Ollama ì„¤ì • (í•„ìˆ˜)

- [ ] Ollama ì„¤ì¹˜ ì™„ë£Œ
- [ ] Ollama ì„œë²„ ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ í™•ì¸
- [ ] Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ìµœì†Œ 1ê°œ)
  - [ ] llama3:8b (ê¶Œì¥)
  - [ ] qwen3:8b (ê¶Œì¥)
  - [ ] codellama:7b (ì½”ë“œ íŠ¹í™”)
- [ ] Ollama í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
- [ ] Ollama ì—°ê²° í…ŒìŠ¤íŠ¸ ì„±ê³µ

### ì‹¤í–‰ ì¤€ë¹„

- [ ] í…ŒìŠ¤íŠ¸ ë°ì´í„° í™•ì¸ ì™„ë£Œ
- [ ] ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ëª…ë ¹ì–´ ì¤€ë¹„
- [ ] ê²°ê³¼ ì €ì¥ ê²½ë¡œ í™•ì¸

## ğŸ¯ ê¶Œì¥ ì‹¤í–‰ ìˆœì„œ

### Ollama ìœ„ì£¼ ì‚¬ìš© (Colab Pro/Pro+)

1. **ì²˜ìŒ ì‹¤í–‰ (í…ŒìŠ¤íŠ¸)**
   ```python
   !python benchmark_runner.py --providers ollama --agents source_code --limit 3
   ```

2. **ì •ìƒ ì‘ë™ í™•ì¸ í›„**
   ```python
   !python benchmark_runner.py --providers ollama --agents source_code assembly_binary --limit 5
   ```

3. **ì—¬ëŸ¬ Ollama ëª¨ë¸ ë¹„êµ**
   ```python
   # LLaMA 3
   os.environ['OLLAMA_MODEL'] = 'llama3:8b'
   !python benchmark_runner.py --providers ollama --agents source_code --limit 10

   # Qwen 3
   os.environ['OLLAMA_MODEL'] = 'qwen3:8b'
   !python benchmark_runner.py --providers ollama --agents source_code --limit 10
   ```

4. **ì „ì²´ ë²¤ì¹˜ë§ˆí¬ (Ollama + API ì„ íƒ)**
   ```python
   # Ollamaë§Œ ì‚¬ìš©
   !python benchmark_runner.py --providers ollama --agents source_code assembly_binary logs_config --limit 20

   # APIì™€ í•¨ê»˜ ë¹„êµ (ì„ íƒ)
   !python benchmark_runner.py --providers google ollama --agents source_code assembly_binary logs_config --limit 10
   ```

**ğŸ’¡ Colab Pro/Pro+ ì‚¬ìš© íŒ:**
- ë” ë§ì€ GPU/ë©”ëª¨ë¦¬ë¥¼ í™œìš©í•˜ì—¬ í° ëª¨ë¸ ì‹¤í–‰ ê°€ëŠ¥
- llama3:70b ê°™ì€ ëŒ€í˜• ëª¨ë¸ë„ í…ŒìŠ¤íŠ¸ ê°€ëŠ¥
- ë³‘ë ¬ ì‹¤í–‰ìœ¼ë¡œ ì†ë„ í–¥ìƒ ê°€ëŠ¥
- ëŸ°íƒ€ì„ ì—°ê²° ì‹œê°„ì´ ê¸¸ì–´ ì¥ì‹œê°„ ë²¤ì¹˜ë§ˆí¬ ê°€ëŠ¥

## ğŸ“ ì§€ì› ë° ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œ

1. **Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨**: ìœ„ì˜ "Ollama ì„œë²„ ì—°ê²° ì‹¤íŒ¨" ì„¹ì…˜ ì°¸ì¡°
2. **ë©”ëª¨ë¦¬ ë¶€ì¡±**: í…ŒìŠ¤íŠ¸ ìˆ˜ ì œí•œ (`--limit 3`)
3. **ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨**: ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ ë° ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ

### ì¶”ê°€ ì§€ì›

- Colab ë…¸íŠ¸ë¶ ëŸ°íƒ€ì„ ì¬ì‹œì‘: `ëŸ°íƒ€ì„` â†’ `ëŸ°íƒ€ì„ ë‹¤ì‹œ ì‹œì‘`
- Ollama ì„œë²„ ì¬ì‹œì‘: ìœ„ì˜ ë¬¸ì œ í•´ê²° ì„¹ì…˜ ì°¸ì¡°
- GitHub Issuesì— ë¬¸ì˜

## ğŸ’¡ Colab Pro/Pro+ ìµœì í™” íŒ

### ë¦¬ì†ŒìŠ¤ í™œìš©

```python
# GPU ì‚¬ìš© í™•ì¸
!nvidia-smi

# ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
!free -h

# ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
!df -h
```

### ëŒ€í˜• ëª¨ë¸ í™œìš©

```python
# Colab Pro+ì—ì„œ 70B ëª¨ë¸ ì‚¬ìš©
!ollama pull llama3:70b
os.environ['OLLAMA_MODEL'] = 'llama3:70b'
!python benchmark_runner.py --providers ollama --agents source_code --limit 5
```

### ì¥ì‹œê°„ ì‹¤í–‰

```python
# ë°±ê·¸ë¼ìš´ë“œ ì‹¤í–‰ìœ¼ë¡œ ì—°ê²° ëŠê¹€ ë°©ì§€
import time
from IPython.display import Javascript

# 1ì‹œê°„ë§ˆë‹¤ ìë™ í´ë¦­ (ì—°ê²° ìœ ì§€)
display(Javascript('''
  setInterval(function() {
    document.querySelector("colab-connect-button").click()
  }, 3600000);
'''))
```

---

## ğŸ‰ ì™„ë£Œ!

ì´ ê°€ì´ë“œë¥¼ ë”°ë¼ Google Colab Pro/Pro+ì—ì„œ Ollamaë¥¼ ì‚¬ìš©í•œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì„±ê³µì ìœ¼ë¡œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ìš”ì•½:**
1. Ollama ì„¤ì¹˜ ë° ì„œë²„ ì‹¤í–‰
2. ì›í•˜ëŠ” ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (llama3:8b, qwen3:8b ê¶Œì¥)
3. ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ (`--providers ollama`)
4. ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”

ëª¨ë“  ë‹¨ê³„ê°€ ì •ìƒ ì‘ë™í•˜ë©´ ì–‘ì ì·¨ì•½ ì•”í˜¸ ì•Œê³ ë¦¬ì¦˜ íƒì§€ ì„±ëŠ¥ì„ í‰ê°€í•˜ê³  ë‹¤ì–‘í•œ LLM ëª¨ë¸ì„ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
